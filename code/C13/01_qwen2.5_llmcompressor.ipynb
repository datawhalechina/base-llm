{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 使用 llmcompressor 对 Qwen2.5-7B-Instruct 做 GPTQ & AWQ 量化\n",
        "\n",
        "本 Notebook 演示如何基于 `llmcompressor` 库，对 `Qwen/Qwen2.5-7B-Instruct` 分别应用 **GPTQ** 与 **AWQ** 量化，\n",
        "并加载量化后的检查点进行对话推理。代码风格沿用你当前的 Notebook 写法。\n",
        "\n",
        "这里直接使用 llmcompressor 提供的统一 API，而不是手动调用 `auto-gptq` / `awq` 等底层库。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# 安装依赖（如环境已具备可跳过）\n",
        "%pip install -q \"transformers>=4.54.0,<=4.57.3\" accelerate llmcompressor datasets\n",
        "\n",
        "# llmcompressor 内部已经集成 GPTQ / AWQ 等算法，一般无需手动安装 auto-gptq / awq 等库。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from llmcompressor.modifiers.quantization import GPTQModifier\n",
        "from llmcompressor import oneshot\n",
        "\n",
        "# 基础配置：Qwen2.5-7B 指令模型\n",
        "base_model_id = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "\n",
        "# 设备配置（优先使用 GPU）\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 一、使用 llmcompressor + GPTQ 对 Qwen2.5-7B-Instruct 进行量化\n",
        "\n",
        "这一节使用 `GPTQModifier` + `oneshot` API，对基座模型做权重量化（示例采用 `W4A16` 配置，仅作教学演示）。\n",
        "\n",
        "默认使用公开数据集 `open_platypus` 作为校准集，你也可以在熟悉流程后替换为自己的中文数据集。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5729aeea3fd44597a98ad86b2d793b35",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizing:   0%|          | 0/24926 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T03:57:26.694798+0800 | reset | INFO - Compression lifecycle reset\n",
            "2025-12-19T03:57:26.702409+0800 | from_modifiers | INFO - Creating recipe from modifiers\n",
            "2025-12-19T03:57:26.741739+0800 | initialize | INFO - Compression lifecycle initialized for 1 modifiers\n",
            "2025-12-19T03:57:26.741739+0800 | IndependentPipeline | INFO - Inferred `SequentialPipeline` for `GPTQModifier`\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Preparing cache: 100%|██████████| 128/128 [00:00<00:00, 686.14it/s]\n",
            "(1/29): Calibrating: 100%|██████████| 128/128 [00:07<00:00, 16.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T03:57:34.951606+0800 | compress_modules | INFO - Quantizing model.layers.0.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T03:57:36.204668+0800 | compress | METRIC - time 1.25s\n",
            "2025-12-19T03:57:36.206047+0800 | compress | METRIC - error 1758.54\n",
            "2025-12-19T03:57:36.262468+0800 | compress | METRIC - GPU 0 | usage: 30.75% | total memory: 8 GB\n",
            "2025-12-19T03:57:36.263464+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T03:57:36.264447+0800 | compress_modules | INFO - Quantizing model.layers.0.self_attn.k_proj using 128 samples\n",
            "2025-12-19T03:57:37.072069+0800 | compress | METRIC - time 0.81s\n",
            "2025-12-19T03:57:37.072069+0800 | compress | METRIC - error 273.71\n",
            "2025-12-19T03:57:37.087577+0800 | compress | METRIC - GPU 0 | usage: 30.75% | total memory: 8 GB\n",
            "2025-12-19T03:57:37.088577+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T03:57:37.088577+0800 | compress_modules | INFO - Quantizing model.layers.0.self_attn.v_proj using 128 samples\n",
            "2025-12-19T03:57:37.918929+0800 | compress | METRIC - time 0.83s\n",
            "2025-12-19T03:57:37.920431+0800 | compress | METRIC - error 31.58\n",
            "2025-12-19T03:57:37.930470+0800 | compress | METRIC - GPU 0 | usage: 30.75% | total memory: 8 GB\n",
            "2025-12-19T03:57:37.930470+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T03:57:37.931554+0800 | compress_modules | INFO - Quantizing model.layers.0.self_attn.o_proj using 128 samples\n",
            "2025-12-19T03:57:38.726938+0800 | compress | METRIC - time 0.79s\n",
            "2025-12-19T03:57:38.727960+0800 | compress | METRIC - error 212.37\n",
            "2025-12-19T03:57:38.742977+0800 | compress | METRIC - GPU 0 | usage: 30.78% | total memory: 8 GB\n",
            "2025-12-19T03:57:38.742977+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T03:57:38.743977+0800 | compress_modules | INFO - Quantizing model.layers.0.mlp.gate_proj using 128 samples\n",
            "2025-12-19T03:57:39.593519+0800 | compress | METRIC - time 0.85s\n",
            "2025-12-19T03:57:39.594522+0800 | compress | METRIC - error 3027.93\n",
            "2025-12-19T03:57:39.613891+0800 | compress | METRIC - GPU 0 | usage: 30.78% | total memory: 8 GB\n",
            "2025-12-19T03:57:39.614891+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T03:57:39.615890+0800 | compress_modules | INFO - Quantizing model.layers.0.mlp.up_proj using 128 samples\n",
            "2025-12-19T03:57:40.470388+0800 | compress | METRIC - time 0.85s\n",
            "2025-12-19T03:57:40.471312+0800 | compress | METRIC - error 2085.66\n",
            "2025-12-19T03:57:40.486877+0800 | compress | METRIC - GPU 0 | usage: 30.78% | total memory: 8 GB\n",
            "2025-12-19T03:57:40.487902+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T03:57:40.487902+0800 | compress_modules | INFO - Quantizing model.layers.0.mlp.down_proj using 128 samples\n",
            "2025-12-19T03:57:45.680751+0800 | compress | METRIC - time 5.19s\n",
            "2025-12-19T03:57:45.681868+0800 | compress | METRIC - error 162.04\n",
            "2025-12-19T03:57:45.694357+0800 | compress | METRIC - GPU 0 | usage: 38.30% | total memory: 8 GB\n",
            "2025-12-19T03:57:45.694357+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(1/29): Propagating: 100%|██████████| 128/128 [00:12<00:00,  9.97it/s]\n",
            "(2/29): Calibrating: 100%|██████████| 128/128 [00:07<00:00, 16.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T03:58:06.946569+0800 | compress_modules | INFO - Quantizing model.layers.1.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T03:58:07.831546+0800 | compress | METRIC - time 0.88s\n",
            "2025-12-19T03:58:07.832675+0800 | compress | METRIC - error 1081.88\n",
            "2025-12-19T03:58:07.864100+0800 | compress | METRIC - GPU 0 | usage: 30.87% | total memory: 8 GB\n",
            "2025-12-19T03:58:07.864100+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T03:58:07.865100+0800 | compress_modules | INFO - Quantizing model.layers.1.self_attn.k_proj using 128 samples\n",
            "2025-12-19T03:58:08.739470+0800 | compress | METRIC - time 0.87s\n",
            "2025-12-19T03:58:08.740471+0800 | compress | METRIC - error 314.30\n",
            "2025-12-19T03:58:08.767158+0800 | compress | METRIC - GPU 0 | usage: 30.87% | total memory: 8 GB\n",
            "2025-12-19T03:58:08.768170+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T03:58:08.769063+0800 | compress_modules | INFO - Quantizing model.layers.1.self_attn.v_proj using 128 samples\n",
            "2025-12-19T03:58:09.596606+0800 | compress | METRIC - time 0.83s\n",
            "2025-12-19T03:58:09.596606+0800 | compress | METRIC - error 71.40\n",
            "2025-12-19T03:58:09.621499+0800 | compress | METRIC - GPU 0 | usage: 30.87% | total memory: 8 GB\n",
            "2025-12-19T03:58:09.622843+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T03:58:09.623844+0800 | compress_modules | INFO - Quantizing model.layers.1.self_attn.o_proj using 128 samples\n",
            "2025-12-19T03:58:10.479883+0800 | compress | METRIC - time 0.86s\n",
            "2025-12-19T03:58:10.479883+0800 | compress | METRIC - error 111.12\n",
            "2025-12-19T03:58:10.511431+0800 | compress | METRIC - GPU 0 | usage: 30.90% | total memory: 8 GB\n",
            "2025-12-19T03:58:10.512510+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T03:58:10.513511+0800 | compress_modules | INFO - Quantizing model.layers.1.mlp.gate_proj using 128 samples\n",
            "2025-12-19T03:58:11.410210+0800 | compress | METRIC - time 0.90s\n",
            "2025-12-19T03:58:11.411714+0800 | compress | METRIC - error 100338.75\n",
            "2025-12-19T03:58:11.425438+0800 | compress | METRIC - GPU 0 | usage: 30.90% | total memory: 8 GB\n",
            "2025-12-19T03:58:11.426435+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T03:58:11.427434+0800 | compress_modules | INFO - Quantizing model.layers.1.mlp.up_proj using 128 samples\n",
            "2025-12-19T03:58:12.343560+0800 | compress | METRIC - time 0.92s\n",
            "2025-12-19T03:58:12.344064+0800 | compress | METRIC - error 82340.94\n",
            "2025-12-19T03:58:12.364573+0800 | compress | METRIC - GPU 0 | usage: 30.90% | total memory: 8 GB\n",
            "2025-12-19T03:58:12.365290+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T03:58:12.366358+0800 | compress_modules | INFO - Quantizing model.layers.1.mlp.down_proj using 128 samples\n",
            "2025-12-19T03:58:17.784558+0800 | compress | METRIC - time 5.42s\n",
            "2025-12-19T03:58:17.785556+0800 | compress | METRIC - error 6433.28\n",
            "2025-12-19T03:58:17.806561+0800 | compress | METRIC - GPU 0 | usage: 38.42% | total memory: 8 GB\n",
            "2025-12-19T03:58:17.807560+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(2/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 77.28it/s]\n",
            "(3/29): Calibrating: 100%|██████████| 128/128 [00:06<00:00, 19.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T03:58:26.044380+0800 | compress_modules | INFO - Quantizing model.layers.2.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T03:58:26.985406+0800 | compress | METRIC - time 0.94s\n",
            "2025-12-19T03:58:26.986406+0800 | compress | METRIC - error 3300.75\n",
            "2025-12-19T03:58:27.000613+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T03:58:27.001612+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T03:58:27.001612+0800 | compress_modules | INFO - Quantizing model.layers.2.self_attn.k_proj using 128 samples\n",
            "2025-12-19T03:58:27.818319+0800 | compress | METRIC - time 0.82s\n",
            "2025-12-19T03:58:27.818319+0800 | compress | METRIC - error 703.74\n",
            "2025-12-19T03:58:27.841379+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T03:58:27.842389+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T03:58:27.843384+0800 | compress_modules | INFO - Quantizing model.layers.2.self_attn.v_proj using 128 samples\n",
            "2025-12-19T03:58:28.671325+0800 | compress | METRIC - time 0.83s\n",
            "2025-12-19T03:58:28.671951+0800 | compress | METRIC - error 293.30\n",
            "2025-12-19T03:58:28.695954+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T03:58:28.696953+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T03:58:28.697952+0800 | compress_modules | INFO - Quantizing model.layers.2.self_attn.o_proj using 128 samples\n",
            "2025-12-19T03:58:29.536662+0800 | compress | METRIC - time 0.84s\n",
            "2025-12-19T03:58:29.537645+0800 | compress | METRIC - error 62.42\n",
            "2025-12-19T03:58:29.548334+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T03:58:29.549336+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T03:58:29.550333+0800 | compress_modules | INFO - Quantizing model.layers.2.mlp.gate_proj using 128 samples\n",
            "2025-12-19T03:58:30.398599+0800 | compress | METRIC - time 0.85s\n",
            "2025-12-19T03:58:30.398599+0800 | compress | METRIC - error 74248.27\n",
            "2025-12-19T03:58:30.413329+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T03:58:30.414316+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T03:58:30.415312+0800 | compress_modules | INFO - Quantizing model.layers.2.mlp.up_proj using 128 samples\n",
            "2025-12-19T03:58:31.313444+0800 | compress | METRIC - time 0.90s\n",
            "2025-12-19T03:58:31.314443+0800 | compress | METRIC - error 48972.42\n",
            "2025-12-19T03:58:31.337682+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T03:58:31.338686+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T03:58:31.339680+0800 | compress_modules | INFO - Quantizing model.layers.2.mlp.down_proj using 128 samples\n",
            "2025-12-19T03:58:37.002345+0800 | compress | METRIC - time 5.66s\n",
            "2025-12-19T03:58:37.002345+0800 | compress | METRIC - error 18181.68\n",
            "2025-12-19T03:58:37.013379+0800 | compress | METRIC - GPU 0 | usage: 38.44% | total memory: 8 GB\n",
            "2025-12-19T03:58:37.014345+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(3/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 73.86it/s]\n",
            "(4/29): Calibrating: 100%|██████████| 128/128 [00:06<00:00, 19.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T03:58:45.368502+0800 | compress_modules | INFO - Quantizing model.layers.3.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T03:58:46.238556+0800 | compress | METRIC - time 0.87s\n",
            "2025-12-19T03:58:46.239556+0800 | compress | METRIC - error 2886.40\n",
            "2025-12-19T03:58:46.260754+0800 | compress | METRIC - GPU 0 | usage: 30.82% | total memory: 8 GB\n",
            "2025-12-19T03:58:46.261752+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T03:58:46.262283+0800 | compress_modules | INFO - Quantizing model.layers.3.self_attn.k_proj using 128 samples\n",
            "2025-12-19T03:58:47.087434+0800 | compress | METRIC - time 0.82s\n",
            "2025-12-19T03:58:47.087434+0800 | compress | METRIC - error 609.12\n",
            "2025-12-19T03:58:47.102747+0800 | compress | METRIC - GPU 0 | usage: 30.82% | total memory: 8 GB\n",
            "2025-12-19T03:58:47.103743+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T03:58:47.104740+0800 | compress_modules | INFO - Quantizing model.layers.3.self_attn.v_proj using 128 samples\n",
            "2025-12-19T03:58:47.979909+0800 | compress | METRIC - time 0.87s\n",
            "2025-12-19T03:58:47.981434+0800 | compress | METRIC - error 345.62\n",
            "2025-12-19T03:58:48.004883+0800 | compress | METRIC - GPU 0 | usage: 30.82% | total memory: 8 GB\n",
            "2025-12-19T03:58:48.004883+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T03:58:48.005963+0800 | compress_modules | INFO - Quantizing model.layers.3.self_attn.o_proj using 128 samples\n",
            "2025-12-19T03:58:48.843230+0800 | compress | METRIC - time 0.84s\n",
            "2025-12-19T03:58:48.843230+0800 | compress | METRIC - error 96.04\n",
            "2025-12-19T03:58:48.862369+0800 | compress | METRIC - GPU 0 | usage: 30.82% | total memory: 8 GB\n",
            "2025-12-19T03:58:48.863370+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T03:58:48.864370+0800 | compress_modules | INFO - Quantizing model.layers.3.mlp.gate_proj using 128 samples\n",
            "2025-12-19T03:58:49.752685+0800 | compress | METRIC - time 0.89s\n",
            "2025-12-19T03:58:49.753704+0800 | compress | METRIC - error 51109.58\n",
            "2025-12-19T03:58:49.765412+0800 | compress | METRIC - GPU 0 | usage: 30.82% | total memory: 8 GB\n",
            "2025-12-19T03:58:49.766440+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T03:58:49.766440+0800 | compress_modules | INFO - Quantizing model.layers.3.mlp.up_proj using 128 samples\n",
            "2025-12-19T03:58:50.633418+0800 | compress | METRIC - time 0.87s\n",
            "2025-12-19T03:58:50.633418+0800 | compress | METRIC - error 28249.36\n",
            "2025-12-19T03:58:50.650539+0800 | compress | METRIC - GPU 0 | usage: 30.82% | total memory: 8 GB\n",
            "2025-12-19T03:58:50.651560+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T03:58:50.656870+0800 | compress_modules | INFO - Quantizing model.layers.3.mlp.down_proj using 128 samples\n",
            "2025-12-19T03:58:55.937449+0800 | compress | METRIC - time 5.28s\n",
            "2025-12-19T03:58:55.938435+0800 | compress | METRIC - error 1638.06\n",
            "2025-12-19T03:58:55.950380+0800 | compress | METRIC - GPU 0 | usage: 38.34% | total memory: 8 GB\n",
            "2025-12-19T03:58:55.951274+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(4/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 76.09it/s]\n",
            "(5/29): Calibrating: 100%|██████████| 128/128 [00:06<00:00, 19.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T03:59:04.146257+0800 | compress_modules | INFO - Quantizing model.layers.4.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T03:59:05.032876+0800 | compress | METRIC - time 0.89s\n",
            "2025-12-19T03:59:05.032876+0800 | compress | METRIC - error 2613.32\n",
            "2025-12-19T03:59:05.054603+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T03:59:05.055639+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T03:59:05.056601+0800 | compress_modules | INFO - Quantizing model.layers.4.self_attn.k_proj using 128 samples\n",
            "2025-12-19T03:59:05.874229+0800 | compress | METRIC - time 0.82s\n",
            "2025-12-19T03:59:05.875227+0800 | compress | METRIC - error 498.62\n",
            "2025-12-19T03:59:05.893555+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T03:59:05.894555+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T03:59:05.895554+0800 | compress_modules | INFO - Quantizing model.layers.4.self_attn.v_proj using 128 samples\n",
            "2025-12-19T03:59:06.715266+0800 | compress | METRIC - time 0.82s\n",
            "2025-12-19T03:59:06.716283+0800 | compress | METRIC - error 340.07\n",
            "2025-12-19T03:59:06.730464+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T03:59:06.731448+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T03:59:06.731982+0800 | compress_modules | INFO - Quantizing model.layers.4.self_attn.o_proj using 128 samples\n",
            "2025-12-19T03:59:07.587721+0800 | compress | METRIC - time 0.86s\n",
            "2025-12-19T03:59:07.588713+0800 | compress | METRIC - error 233.47\n",
            "2025-12-19T03:59:07.599954+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T03:59:07.601660+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T03:59:07.602700+0800 | compress_modules | INFO - Quantizing model.layers.4.mlp.gate_proj using 128 samples\n",
            "2025-12-19T03:59:08.522591+0800 | compress | METRIC - time 0.92s\n",
            "2025-12-19T03:59:08.523553+0800 | compress | METRIC - error 26186.71\n",
            "2025-12-19T03:59:08.545807+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T03:59:08.546804+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T03:59:08.547804+0800 | compress_modules | INFO - Quantizing model.layers.4.mlp.up_proj using 128 samples\n",
            "2025-12-19T03:59:09.416357+0800 | compress | METRIC - time 0.87s\n",
            "2025-12-19T03:59:09.417374+0800 | compress | METRIC - error 16100.44\n",
            "2025-12-19T03:59:09.436404+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T03:59:09.437398+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T03:59:09.438398+0800 | compress_modules | INFO - Quantizing model.layers.4.mlp.down_proj using 128 samples\n",
            "2025-12-19T03:59:14.909164+0800 | compress | METRIC - time 5.47s\n",
            "2025-12-19T03:59:14.910154+0800 | compress | METRIC - error 745.99\n",
            "2025-12-19T03:59:14.930115+0800 | compress | METRIC - GPU 0 | usage: 38.44% | total memory: 8 GB\n",
            "2025-12-19T03:59:14.930115+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(5/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 75.28it/s]\n",
            "(6/29): Calibrating: 100%|██████████| 128/128 [00:06<00:00, 19.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T03:59:23.183512+0800 | compress_modules | INFO - Quantizing model.layers.5.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T03:59:24.057717+0800 | compress | METRIC - time 0.87s\n",
            "2025-12-19T03:59:24.058717+0800 | compress | METRIC - error 2894.23\n",
            "2025-12-19T03:59:24.070295+0800 | compress | METRIC - GPU 0 | usage: 30.87% | total memory: 8 GB\n",
            "2025-12-19T03:59:24.070295+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T03:59:24.071292+0800 | compress_modules | INFO - Quantizing model.layers.5.self_attn.k_proj using 128 samples\n",
            "2025-12-19T03:59:24.920235+0800 | compress | METRIC - time 0.85s\n",
            "2025-12-19T03:59:24.920235+0800 | compress | METRIC - error 615.77\n",
            "2025-12-19T03:59:24.945323+0800 | compress | METRIC - GPU 0 | usage: 30.87% | total memory: 8 GB\n",
            "2025-12-19T03:59:24.946303+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T03:59:24.947304+0800 | compress_modules | INFO - Quantizing model.layers.5.self_attn.v_proj using 128 samples\n",
            "2025-12-19T03:59:25.787456+0800 | compress | METRIC - time 0.84s\n",
            "2025-12-19T03:59:25.787456+0800 | compress | METRIC - error 508.49\n",
            "2025-12-19T03:59:25.799493+0800 | compress | METRIC - GPU 0 | usage: 30.87% | total memory: 8 GB\n",
            "2025-12-19T03:59:25.799493+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T03:59:25.800464+0800 | compress_modules | INFO - Quantizing model.layers.5.self_attn.o_proj using 128 samples\n",
            "2025-12-19T03:59:26.647903+0800 | compress | METRIC - time 0.85s\n",
            "2025-12-19T03:59:26.647903+0800 | compress | METRIC - error 372.32\n",
            "2025-12-19T03:59:26.660415+0800 | compress | METRIC - GPU 0 | usage: 30.87% | total memory: 8 GB\n",
            "2025-12-19T03:59:26.661414+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T03:59:26.661414+0800 | compress_modules | INFO - Quantizing model.layers.5.mlp.gate_proj using 128 samples\n",
            "2025-12-19T03:59:27.556293+0800 | compress | METRIC - time 0.89s\n",
            "2025-12-19T03:59:27.557294+0800 | compress | METRIC - error 56552.40\n",
            "2025-12-19T03:59:27.575502+0800 | compress | METRIC - GPU 0 | usage: 30.87% | total memory: 8 GB\n",
            "2025-12-19T03:59:27.576502+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T03:59:27.577499+0800 | compress_modules | INFO - Quantizing model.layers.5.mlp.up_proj using 128 samples\n",
            "2025-12-19T03:59:28.409729+0800 | compress | METRIC - time 0.83s\n",
            "2025-12-19T03:59:28.409729+0800 | compress | METRIC - error 37059.32\n",
            "2025-12-19T03:59:28.421352+0800 | compress | METRIC - GPU 0 | usage: 30.87% | total memory: 8 GB\n",
            "2025-12-19T03:59:28.421352+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T03:59:28.422379+0800 | compress_modules | INFO - Quantizing model.layers.5.mlp.down_proj using 128 samples\n",
            "2025-12-19T03:59:33.645461+0800 | compress | METRIC - time 5.22s\n",
            "2025-12-19T03:59:33.646443+0800 | compress | METRIC - error 827.29\n",
            "2025-12-19T03:59:33.669438+0800 | compress | METRIC - GPU 0 | usage: 38.39% | total memory: 8 GB\n",
            "2025-12-19T03:59:33.670438+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(6/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 76.37it/s]\n",
            "(7/29): Calibrating: 100%|██████████| 128/128 [00:06<00:00, 19.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T03:59:41.994988+0800 | compress_modules | INFO - Quantizing model.layers.6.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T03:59:42.845740+0800 | compress | METRIC - time 0.85s\n",
            "2025-12-19T03:59:42.846740+0800 | compress | METRIC - error 3676.75\n",
            "2025-12-19T03:59:42.870435+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T03:59:42.870435+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T03:59:42.871436+0800 | compress_modules | INFO - Quantizing model.layers.6.self_attn.k_proj using 128 samples\n",
            "2025-12-19T03:59:43.637368+0800 | compress | METRIC - time 0.76s\n",
            "2025-12-19T03:59:43.638386+0800 | compress | METRIC - error 768.72\n",
            "2025-12-19T03:59:43.649611+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T03:59:43.649611+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T03:59:43.650588+0800 | compress_modules | INFO - Quantizing model.layers.6.self_attn.v_proj using 128 samples\n",
            "2025-12-19T03:59:44.431336+0800 | compress | METRIC - time 0.78s\n",
            "2025-12-19T03:59:44.431336+0800 | compress | METRIC - error 413.47\n",
            "2025-12-19T03:59:44.443454+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T03:59:44.444451+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T03:59:44.444451+0800 | compress_modules | INFO - Quantizing model.layers.6.self_attn.o_proj using 128 samples\n",
            "2025-12-19T03:59:45.247869+0800 | compress | METRIC - time 0.80s\n",
            "2025-12-19T03:59:45.248862+0800 | compress | METRIC - error 143.53\n",
            "2025-12-19T03:59:45.267502+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T03:59:45.268500+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T03:59:45.268500+0800 | compress_modules | INFO - Quantizing model.layers.6.mlp.gate_proj using 128 samples\n",
            "2025-12-19T03:59:46.118903+0800 | compress | METRIC - time 0.85s\n",
            "2025-12-19T03:59:46.119903+0800 | compress | METRIC - error 16169.98\n",
            "2025-12-19T03:59:46.138384+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T03:59:46.139382+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T03:59:46.140381+0800 | compress_modules | INFO - Quantizing model.layers.6.mlp.up_proj using 128 samples\n",
            "2025-12-19T03:59:46.989524+0800 | compress | METRIC - time 0.85s\n",
            "2025-12-19T03:59:46.990526+0800 | compress | METRIC - error 13564.61\n",
            "2025-12-19T03:59:47.011894+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T03:59:47.011894+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T03:59:47.012904+0800 | compress_modules | INFO - Quantizing model.layers.6.mlp.down_proj using 128 samples\n",
            "2025-12-19T03:59:52.101461+0800 | compress | METRIC - time 5.09s\n",
            "2025-12-19T03:59:52.101461+0800 | compress | METRIC - error 1179.87\n",
            "2025-12-19T03:59:52.119549+0800 | compress | METRIC - GPU 0 | usage: 38.44% | total memory: 8 GB\n",
            "2025-12-19T03:59:52.120550+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(7/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 74.28it/s]\n",
            "(8/29): Calibrating: 100%|██████████| 128/128 [00:06<00:00, 19.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:00:00.421669+0800 | compress_modules | INFO - Quantizing model.layers.7.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:00:01.263804+0800 | compress | METRIC - time 0.84s\n",
            "2025-12-19T04:00:01.263804+0800 | compress | METRIC - error 2015.90\n",
            "2025-12-19T04:00:01.279859+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T04:00:01.281364+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T04:00:01.281364+0800 | compress_modules | INFO - Quantizing model.layers.7.self_attn.k_proj using 128 samples\n",
            "2025-12-19T04:00:02.137559+0800 | compress | METRIC - time 0.86s\n",
            "2025-12-19T04:00:02.137559+0800 | compress | METRIC - error 388.94\n",
            "2025-12-19T04:00:02.160476+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T04:00:02.161476+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:00:02.161476+0800 | compress_modules | INFO - Quantizing model.layers.7.self_attn.v_proj using 128 samples\n",
            "2025-12-19T04:00:03.015336+0800 | compress | METRIC - time 0.85s\n",
            "2025-12-19T04:00:03.015336+0800 | compress | METRIC - error 311.87\n",
            "2025-12-19T04:00:03.039418+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T04:00:03.040413+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:00:03.041922+0800 | compress_modules | INFO - Quantizing model.layers.7.self_attn.o_proj using 128 samples\n",
            "2025-12-19T04:00:03.854327+0800 | compress | METRIC - time 0.81s\n",
            "2025-12-19T04:00:03.854327+0800 | compress | METRIC - error 314.00\n",
            "2025-12-19T04:00:03.879389+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T04:00:03.880385+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T04:00:03.881384+0800 | compress_modules | INFO - Quantizing model.layers.7.mlp.gate_proj using 128 samples\n",
            "2025-12-19T04:00:04.769672+0800 | compress | METRIC - time 0.89s\n",
            "2025-12-19T04:00:04.770672+0800 | compress | METRIC - error 13399.34\n",
            "2025-12-19T04:00:04.792222+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T04:00:04.793272+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:00:04.794222+0800 | compress_modules | INFO - Quantizing model.layers.7.mlp.up_proj using 128 samples\n",
            "2025-12-19T04:00:05.643531+0800 | compress | METRIC - time 0.85s\n",
            "2025-12-19T04:00:05.643531+0800 | compress | METRIC - error 12842.21\n",
            "2025-12-19T04:00:05.659338+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T04:00:05.660361+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:00:05.661339+0800 | compress_modules | INFO - Quantizing model.layers.7.mlp.down_proj using 128 samples\n",
            "2025-12-19T04:00:10.969788+0800 | compress | METRIC - time 5.31s\n",
            "2025-12-19T04:00:10.969788+0800 | compress | METRIC - error 1324.84\n",
            "2025-12-19T04:00:10.983859+0800 | compress | METRIC - GPU 0 | usage: 38.44% | total memory: 8 GB\n",
            "2025-12-19T04:00:10.984858+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(8/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 73.96it/s]\n",
            "(9/29): Calibrating: 100%|██████████| 128/128 [00:06<00:00, 19.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:00:19.327611+0800 | compress_modules | INFO - Quantizing model.layers.8.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:00:20.185354+0800 | compress | METRIC - time 0.86s\n",
            "2025-12-19T04:00:20.186353+0800 | compress | METRIC - error 4255.65\n",
            "2025-12-19T04:00:20.203399+0800 | compress | METRIC - GPU 0 | usage: 30.87% | total memory: 8 GB\n",
            "2025-12-19T04:00:20.204363+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T04:00:20.205364+0800 | compress_modules | INFO - Quantizing model.layers.8.self_attn.k_proj using 128 samples\n",
            "2025-12-19T04:00:20.977281+0800 | compress | METRIC - time 0.77s\n",
            "2025-12-19T04:00:20.977281+0800 | compress | METRIC - error 748.19\n",
            "2025-12-19T04:00:20.994765+0800 | compress | METRIC - GPU 0 | usage: 30.87% | total memory: 8 GB\n",
            "2025-12-19T04:00:20.995764+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:00:20.996763+0800 | compress_modules | INFO - Quantizing model.layers.8.self_attn.v_proj using 128 samples\n",
            "2025-12-19T04:00:21.805202+0800 | compress | METRIC - time 0.81s\n",
            "2025-12-19T04:00:21.806203+0800 | compress | METRIC - error 471.47\n",
            "2025-12-19T04:00:21.823051+0800 | compress | METRIC - GPU 0 | usage: 30.88% | total memory: 8 GB\n",
            "2025-12-19T04:00:21.824078+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:00:21.824078+0800 | compress_modules | INFO - Quantizing model.layers.8.self_attn.o_proj using 128 samples\n",
            "2025-12-19T04:00:22.668006+0800 | compress | METRIC - time 0.84s\n",
            "2025-12-19T04:00:22.668554+0800 | compress | METRIC - error 505.97\n",
            "2025-12-19T04:00:22.692813+0800 | compress | METRIC - GPU 0 | usage: 30.88% | total memory: 8 GB\n",
            "2025-12-19T04:00:22.693813+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T04:00:22.693813+0800 | compress_modules | INFO - Quantizing model.layers.8.mlp.gate_proj using 128 samples\n",
            "2025-12-19T04:00:23.532805+0800 | compress | METRIC - time 0.84s\n",
            "2025-12-19T04:00:23.532805+0800 | compress | METRIC - error 16590.74\n",
            "2025-12-19T04:00:23.547882+0800 | compress | METRIC - GPU 0 | usage: 30.88% | total memory: 8 GB\n",
            "2025-12-19T04:00:23.548880+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:00:23.549878+0800 | compress_modules | INFO - Quantizing model.layers.8.mlp.up_proj using 128 samples\n",
            "2025-12-19T04:00:24.415678+0800 | compress | METRIC - time 0.87s\n",
            "2025-12-19T04:00:24.416677+0800 | compress | METRIC - error 15265.84\n",
            "2025-12-19T04:00:24.437434+0800 | compress | METRIC - GPU 0 | usage: 30.88% | total memory: 8 GB\n",
            "2025-12-19T04:00:24.438432+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:00:24.439431+0800 | compress_modules | INFO - Quantizing model.layers.8.mlp.down_proj using 128 samples\n",
            "2025-12-19T04:00:29.609745+0800 | compress | METRIC - time 5.17s\n",
            "2025-12-19T04:00:29.610422+0800 | compress | METRIC - error 1388.33\n",
            "2025-12-19T04:00:29.634475+0800 | compress | METRIC - GPU 0 | usage: 38.40% | total memory: 8 GB\n",
            "2025-12-19T04:00:29.635474+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(9/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 74.51it/s]\n",
            "(10/29): Calibrating: 100%|██████████| 128/128 [00:06<00:00, 19.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:00:38.049666+0800 | compress_modules | INFO - Quantizing model.layers.9.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:00:38.941621+0800 | compress | METRIC - time 0.89s\n",
            "2025-12-19T04:00:38.942706+0800 | compress | METRIC - error 4203.00\n",
            "2025-12-19T04:00:38.966544+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T04:00:38.967520+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T04:00:38.968521+0800 | compress_modules | INFO - Quantizing model.layers.9.self_attn.k_proj using 128 samples\n",
            "2025-12-19T04:00:39.812018+0800 | compress | METRIC - time 0.84s\n",
            "2025-12-19T04:00:39.812018+0800 | compress | METRIC - error 854.79\n",
            "2025-12-19T04:00:39.837132+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T04:00:39.838155+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:00:39.839132+0800 | compress_modules | INFO - Quantizing model.layers.9.self_attn.v_proj using 128 samples\n",
            "2025-12-19T04:00:40.682623+0800 | compress | METRIC - time 0.84s\n",
            "2025-12-19T04:00:40.683622+0800 | compress | METRIC - error 495.63\n",
            "2025-12-19T04:00:40.695175+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T04:00:40.696194+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:00:40.697171+0800 | compress_modules | INFO - Quantizing model.layers.9.self_attn.o_proj using 128 samples\n",
            "2025-12-19T04:00:41.578838+0800 | compress | METRIC - time 0.88s\n",
            "2025-12-19T04:00:41.579836+0800 | compress | METRIC - error 462.81\n",
            "2025-12-19T04:00:41.597746+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T04:00:41.598849+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T04:00:41.599744+0800 | compress_modules | INFO - Quantizing model.layers.9.mlp.gate_proj using 128 samples\n",
            "2025-12-19T04:00:42.569684+0800 | compress | METRIC - time 0.97s\n",
            "2025-12-19T04:00:42.569684+0800 | compress | METRIC - error 17775.47\n",
            "2025-12-19T04:00:42.593248+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T04:00:42.594249+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:00:42.594249+0800 | compress_modules | INFO - Quantizing model.layers.9.mlp.up_proj using 128 samples\n",
            "2025-12-19T04:00:43.467510+0800 | compress | METRIC - time 0.87s\n",
            "2025-12-19T04:00:43.467510+0800 | compress | METRIC - error 17220.61\n",
            "2025-12-19T04:00:43.483574+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T04:00:43.484579+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:00:43.485578+0800 | compress_modules | INFO - Quantizing model.layers.9.mlp.down_proj using 128 samples\n",
            "2025-12-19T04:00:48.632445+0800 | compress | METRIC - time 5.15s\n",
            "2025-12-19T04:00:48.632445+0800 | compress | METRIC - error 2107.70\n",
            "2025-12-19T04:00:48.643900+0800 | compress | METRIC - GPU 0 | usage: 38.44% | total memory: 8 GB\n",
            "2025-12-19T04:00:48.643900+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(10/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 75.05it/s]\n",
            "(11/29): Calibrating: 100%|██████████| 128/128 [00:06<00:00, 19.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:00:56.982591+0800 | compress_modules | INFO - Quantizing model.layers.10.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:00:57.891495+0800 | compress | METRIC - time 0.91s\n",
            "2025-12-19T04:00:57.892002+0800 | compress | METRIC - error 4530.18\n",
            "2025-12-19T04:00:57.918543+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T04:00:57.919548+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T04:00:57.920474+0800 | compress_modules | INFO - Quantizing model.layers.10.self_attn.k_proj using 128 samples\n",
            "2025-12-19T04:00:58.765862+0800 | compress | METRIC - time 0.84s\n",
            "2025-12-19T04:00:58.766866+0800 | compress | METRIC - error 878.22\n",
            "2025-12-19T04:00:58.782935+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T04:00:58.782935+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:00:58.783951+0800 | compress_modules | INFO - Quantizing model.layers.10.self_attn.v_proj using 128 samples\n",
            "2025-12-19T04:00:59.642683+0800 | compress | METRIC - time 0.86s\n",
            "2025-12-19T04:00:59.642683+0800 | compress | METRIC - error 766.89\n",
            "2025-12-19T04:00:59.667935+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T04:00:59.668933+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:00:59.669933+0800 | compress_modules | INFO - Quantizing model.layers.10.self_attn.o_proj using 128 samples\n",
            "2025-12-19T04:01:00.532649+0800 | compress | METRIC - time 0.86s\n",
            "2025-12-19T04:01:00.533648+0800 | compress | METRIC - error 604.80\n",
            "2025-12-19T04:01:00.558486+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T04:01:00.559486+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T04:01:00.560486+0800 | compress_modules | INFO - Quantizing model.layers.10.mlp.gate_proj using 128 samples\n",
            "2025-12-19T04:01:01.446227+0800 | compress | METRIC - time 0.89s\n",
            "2025-12-19T04:01:01.446227+0800 | compress | METRIC - error 17908.56\n",
            "2025-12-19T04:01:01.459726+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T04:01:01.461263+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:01:01.462277+0800 | compress_modules | INFO - Quantizing model.layers.10.mlp.up_proj using 128 samples\n",
            "2025-12-19T04:01:02.282606+0800 | compress | METRIC - time 0.82s\n",
            "2025-12-19T04:01:02.283624+0800 | compress | METRIC - error 16878.93\n",
            "2025-12-19T04:01:02.305728+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T04:01:02.306727+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:01:02.307218+0800 | compress_modules | INFO - Quantizing model.layers.10.mlp.down_proj using 128 samples\n",
            "2025-12-19T04:01:07.562967+0800 | compress | METRIC - time 5.25s\n",
            "2025-12-19T04:01:07.563971+0800 | compress | METRIC - error 1803.82\n",
            "2025-12-19T04:01:07.574170+0800 | compress | METRIC - GPU 0 | usage: 38.44% | total memory: 8 GB\n",
            "2025-12-19T04:01:07.575167+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(11/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 74.31it/s]\n",
            "(12/29): Calibrating: 100%|██████████| 128/128 [00:06<00:00, 19.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:01:16.027890+0800 | compress_modules | INFO - Quantizing model.layers.11.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:01:16.904355+0800 | compress | METRIC - time 0.88s\n",
            "2025-12-19T04:01:16.904355+0800 | compress | METRIC - error 5102.84\n",
            "2025-12-19T04:01:16.915932+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T04:01:16.916930+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T04:01:16.917929+0800 | compress_modules | INFO - Quantizing model.layers.11.self_attn.k_proj using 128 samples\n",
            "2025-12-19T04:01:17.784420+0800 | compress | METRIC - time 0.87s\n",
            "2025-12-19T04:01:17.785421+0800 | compress | METRIC - error 994.68\n",
            "2025-12-19T04:01:17.807420+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T04:01:17.808419+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:01:17.809419+0800 | compress_modules | INFO - Quantizing model.layers.11.self_attn.v_proj using 128 samples\n",
            "2025-12-19T04:01:18.634638+0800 | compress | METRIC - time 0.83s\n",
            "2025-12-19T04:01:18.635637+0800 | compress | METRIC - error 711.46\n",
            "2025-12-19T04:01:18.646831+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T04:01:18.646831+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:01:18.647811+0800 | compress_modules | INFO - Quantizing model.layers.11.self_attn.o_proj using 128 samples\n",
            "2025-12-19T04:01:19.496440+0800 | compress | METRIC - time 0.85s\n",
            "2025-12-19T04:01:19.496440+0800 | compress | METRIC - error 550.25\n",
            "2025-12-19T04:01:19.517494+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T04:01:19.518510+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T04:01:19.519493+0800 | compress_modules | INFO - Quantizing model.layers.11.mlp.gate_proj using 128 samples\n",
            "2025-12-19T04:01:20.419882+0800 | compress | METRIC - time 0.90s\n",
            "2025-12-19T04:01:20.419882+0800 | compress | METRIC - error 20462.15\n",
            "2025-12-19T04:01:20.439700+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T04:01:20.441281+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:01:20.441281+0800 | compress_modules | INFO - Quantizing model.layers.11.mlp.up_proj using 128 samples\n",
            "2025-12-19T04:01:21.324639+0800 | compress | METRIC - time 0.88s\n",
            "2025-12-19T04:01:21.324639+0800 | compress | METRIC - error 18001.39\n",
            "2025-12-19T04:01:21.342431+0800 | compress | METRIC - GPU 0 | usage: 30.92% | total memory: 8 GB\n",
            "2025-12-19T04:01:21.343430+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:01:21.344429+0800 | compress_modules | INFO - Quantizing model.layers.11.mlp.down_proj using 128 samples\n",
            "2025-12-19T04:01:26.583799+0800 | compress | METRIC - time 5.24s\n",
            "2025-12-19T04:01:26.584906+0800 | compress | METRIC - error 1823.57\n",
            "2025-12-19T04:01:26.614510+0800 | compress | METRIC - GPU 0 | usage: 38.44% | total memory: 8 GB\n",
            "2025-12-19T04:01:26.615504+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(12/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 75.74it/s]\n",
            "(13/29): Calibrating: 100%|██████████| 128/128 [00:06<00:00, 19.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:01:34.941537+0800 | compress_modules | INFO - Quantizing model.layers.12.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:01:35.893901+0800 | compress | METRIC - time 0.95s\n",
            "2025-12-19T04:01:35.895406+0800 | compress | METRIC - error 6597.79\n",
            "2025-12-19T04:01:35.915406+0800 | compress | METRIC - GPU 0 | usage: 31.19% | total memory: 8 GB\n",
            "2025-12-19T04:01:35.916403+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T04:01:35.917401+0800 | compress_modules | INFO - Quantizing model.layers.12.self_attn.k_proj using 128 samples\n",
            "2025-12-19T04:01:36.899713+0800 | compress | METRIC - time 0.98s\n",
            "2025-12-19T04:01:36.901217+0800 | compress | METRIC - error 1412.56\n",
            "2025-12-19T04:01:36.935263+0800 | compress | METRIC - GPU 0 | usage: 31.19% | total memory: 8 GB\n",
            "2025-12-19T04:01:36.935263+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:01:36.936263+0800 | compress_modules | INFO - Quantizing model.layers.12.self_attn.v_proj using 128 samples\n",
            "2025-12-19T04:01:37.844789+0800 | compress | METRIC - time 0.91s\n",
            "2025-12-19T04:01:37.845789+0800 | compress | METRIC - error 738.65\n",
            "2025-12-19T04:01:37.865574+0800 | compress | METRIC - GPU 0 | usage: 31.19% | total memory: 8 GB\n",
            "2025-12-19T04:01:37.866569+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:01:37.867569+0800 | compress_modules | INFO - Quantizing model.layers.12.self_attn.o_proj using 128 samples\n",
            "2025-12-19T04:01:38.728477+0800 | compress | METRIC - time 0.86s\n",
            "2025-12-19T04:01:38.728477+0800 | compress | METRIC - error 468.82\n",
            "2025-12-19T04:01:38.754344+0800 | compress | METRIC - GPU 0 | usage: 31.19% | total memory: 8 GB\n",
            "2025-12-19T04:01:38.755343+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T04:01:38.757344+0800 | compress_modules | INFO - Quantizing model.layers.12.mlp.gate_proj using 128 samples\n",
            "2025-12-19T04:01:39.659457+0800 | compress | METRIC - time 0.90s\n",
            "2025-12-19T04:01:39.660520+0800 | compress | METRIC - error 20683.21\n",
            "2025-12-19T04:01:39.677718+0800 | compress | METRIC - GPU 0 | usage: 31.19% | total memory: 8 GB\n",
            "2025-12-19T04:01:39.678724+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:01:39.679729+0800 | compress_modules | INFO - Quantizing model.layers.12.mlp.up_proj using 128 samples\n",
            "2025-12-19T04:01:40.574530+0800 | compress | METRIC - time 0.89s\n",
            "2025-12-19T04:01:40.575529+0800 | compress | METRIC - error 18801.88\n",
            "2025-12-19T04:01:40.593983+0800 | compress | METRIC - GPU 0 | usage: 31.19% | total memory: 8 GB\n",
            "2025-12-19T04:01:40.595086+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:01:40.595984+0800 | compress_modules | INFO - Quantizing model.layers.12.mlp.down_proj using 128 samples\n",
            "2025-12-19T04:01:45.875380+0800 | compress | METRIC - time 5.28s\n",
            "2025-12-19T04:01:45.875380+0800 | compress | METRIC - error 1824.28\n",
            "2025-12-19T04:01:45.896411+0800 | compress | METRIC - GPU 0 | usage: 38.71% | total memory: 8 GB\n",
            "2025-12-19T04:01:45.897253+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(13/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 75.90it/s]\n",
            "(14/29): Calibrating: 100%|██████████| 128/128 [00:06<00:00, 19.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:01:54.168629+0800 | compress_modules | INFO - Quantizing model.layers.13.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:01:55.067174+0800 | compress | METRIC - time 0.90s\n",
            "2025-12-19T04:01:55.068189+0800 | compress | METRIC - error 4877.06\n",
            "2025-12-19T04:01:55.079892+0800 | compress | METRIC - GPU 0 | usage: 31.09% | total memory: 8 GB\n",
            "2025-12-19T04:01:55.081458+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T04:01:55.082403+0800 | compress_modules | INFO - Quantizing model.layers.13.self_attn.k_proj using 128 samples\n",
            "2025-12-19T04:01:56.008507+0800 | compress | METRIC - time 0.93s\n",
            "2025-12-19T04:01:56.009135+0800 | compress | METRIC - error 978.50\n",
            "2025-12-19T04:01:56.049333+0800 | compress | METRIC - GPU 0 | usage: 31.09% | total memory: 8 GB\n",
            "2025-12-19T04:01:56.049333+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:01:56.050340+0800 | compress_modules | INFO - Quantizing model.layers.13.self_attn.v_proj using 128 samples\n",
            "2025-12-19T04:01:56.894820+0800 | compress | METRIC - time 0.84s\n",
            "2025-12-19T04:01:56.894820+0800 | compress | METRIC - error 646.23\n",
            "2025-12-19T04:01:56.912765+0800 | compress | METRIC - GPU 0 | usage: 31.09% | total memory: 8 GB\n",
            "2025-12-19T04:01:56.913772+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:01:56.913772+0800 | compress_modules | INFO - Quantizing model.layers.13.self_attn.o_proj using 128 samples\n",
            "2025-12-19T04:01:57.848708+0800 | compress | METRIC - time 0.93s\n",
            "2025-12-19T04:01:57.849705+0800 | compress | METRIC - error 462.37\n",
            "2025-12-19T04:01:57.871934+0800 | compress | METRIC - GPU 0 | usage: 31.09% | total memory: 8 GB\n",
            "2025-12-19T04:01:57.872944+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T04:01:57.873950+0800 | compress_modules | INFO - Quantizing model.layers.13.mlp.gate_proj using 128 samples\n",
            "2025-12-19T04:01:58.767038+0800 | compress | METRIC - time 0.89s\n",
            "2025-12-19T04:01:58.768044+0800 | compress | METRIC - error 19501.56\n",
            "2025-12-19T04:01:58.790284+0800 | compress | METRIC - GPU 0 | usage: 31.09% | total memory: 8 GB\n",
            "2025-12-19T04:01:58.791780+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:01:58.792795+0800 | compress_modules | INFO - Quantizing model.layers.13.mlp.up_proj using 128 samples\n",
            "2025-12-19T04:01:59.674326+0800 | compress | METRIC - time 0.88s\n",
            "2025-12-19T04:01:59.674326+0800 | compress | METRIC - error 18748.83\n",
            "2025-12-19T04:01:59.693267+0800 | compress | METRIC - GPU 0 | usage: 31.09% | total memory: 8 GB\n",
            "2025-12-19T04:01:59.694332+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:01:59.695221+0800 | compress_modules | INFO - Quantizing model.layers.13.mlp.down_proj using 128 samples\n",
            "2025-12-19T04:02:05.155335+0800 | compress | METRIC - time 5.46s\n",
            "2025-12-19T04:02:05.156335+0800 | compress | METRIC - error 1675.22\n",
            "2025-12-19T04:02:05.178888+0800 | compress | METRIC - GPU 0 | usage: 34.85% | total memory: 8 GB\n",
            "2025-12-19T04:02:05.179903+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(14/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 76.27it/s]\n",
            "(15/29): Calibrating: 100%|██████████| 128/128 [00:06<00:00, 19.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:02:13.544845+0800 | compress_modules | INFO - Quantizing model.layers.14.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:02:14.495452+0800 | compress | METRIC - time 0.95s\n",
            "2025-12-19T04:02:14.496469+0800 | compress | METRIC - error 9414.70\n",
            "2025-12-19T04:02:14.519544+0800 | compress | METRIC - GPU 0 | usage: 31.14% | total memory: 8 GB\n",
            "2025-12-19T04:02:14.520521+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T04:02:14.522024+0800 | compress_modules | INFO - Quantizing model.layers.14.self_attn.k_proj using 128 samples\n",
            "2025-12-19T04:02:15.479328+0800 | compress | METRIC - time 0.96s\n",
            "2025-12-19T04:02:15.480328+0800 | compress | METRIC - error 1407.72\n",
            "2025-12-19T04:02:15.498680+0800 | compress | METRIC - GPU 0 | usage: 31.14% | total memory: 8 GB\n",
            "2025-12-19T04:02:15.500315+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:02:15.501331+0800 | compress_modules | INFO - Quantizing model.layers.14.self_attn.v_proj using 128 samples\n",
            "2025-12-19T04:02:16.409721+0800 | compress | METRIC - time 0.91s\n",
            "2025-12-19T04:02:16.409721+0800 | compress | METRIC - error 1078.25\n",
            "2025-12-19T04:02:16.433395+0800 | compress | METRIC - GPU 0 | usage: 31.14% | total memory: 8 GB\n",
            "2025-12-19T04:02:16.434395+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:02:16.435394+0800 | compress_modules | INFO - Quantizing model.layers.14.self_attn.o_proj using 128 samples\n",
            "2025-12-19T04:02:17.349882+0800 | compress | METRIC - time 0.91s\n",
            "2025-12-19T04:02:17.349882+0800 | compress | METRIC - error 477.83\n",
            "2025-12-19T04:02:17.364969+0800 | compress | METRIC - GPU 0 | usage: 31.14% | total memory: 8 GB\n",
            "2025-12-19T04:02:17.365986+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T04:02:17.366965+0800 | compress_modules | INFO - Quantizing model.layers.14.mlp.gate_proj using 128 samples\n",
            "2025-12-19T04:02:18.313328+0800 | compress | METRIC - time 0.95s\n",
            "2025-12-19T04:02:18.313328+0800 | compress | METRIC - error 20830.67\n",
            "2025-12-19T04:02:18.333323+0800 | compress | METRIC - GPU 0 | usage: 31.14% | total memory: 8 GB\n",
            "2025-12-19T04:02:18.334326+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:02:18.335421+0800 | compress_modules | INFO - Quantizing model.layers.14.mlp.up_proj using 128 samples\n",
            "2025-12-19T04:02:19.341492+0800 | compress | METRIC - time 1.01s\n",
            "2025-12-19T04:02:19.342497+0800 | compress | METRIC - error 21202.04\n",
            "2025-12-19T04:02:19.359926+0800 | compress | METRIC - GPU 0 | usage: 31.14% | total memory: 8 GB\n",
            "2025-12-19T04:02:19.361431+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:02:19.361431+0800 | compress_modules | INFO - Quantizing model.layers.14.mlp.down_proj using 128 samples\n",
            "2025-12-19T04:02:24.801467+0800 | compress | METRIC - time 5.44s\n",
            "2025-12-19T04:02:24.801467+0800 | compress | METRIC - error 2207.10\n",
            "2025-12-19T04:02:24.816800+0800 | compress | METRIC - GPU 0 | usage: 38.66% | total memory: 8 GB\n",
            "2025-12-19T04:02:24.816800+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(15/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 75.23it/s]\n",
            "(16/29): Calibrating: 100%|██████████| 128/128 [00:06<00:00, 19.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:02:33.115633+0800 | compress_modules | INFO - Quantizing model.layers.15.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:02:34.053202+0800 | compress | METRIC - time 0.94s\n",
            "2025-12-19T04:02:34.053202+0800 | compress | METRIC - error 10969.96\n",
            "2025-12-19T04:02:34.075402+0800 | compress | METRIC - GPU 0 | usage: 31.24% | total memory: 8 GB\n",
            "2025-12-19T04:02:34.076511+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T04:02:34.077402+0800 | compress_modules | INFO - Quantizing model.layers.15.self_attn.k_proj using 128 samples\n",
            "2025-12-19T04:02:35.049707+0800 | compress | METRIC - time 0.97s\n",
            "2025-12-19T04:02:35.049707+0800 | compress | METRIC - error 1216.44\n",
            "2025-12-19T04:02:35.062550+0800 | compress | METRIC - GPU 0 | usage: 31.24% | total memory: 8 GB\n",
            "2025-12-19T04:02:35.068550+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:02:35.070550+0800 | compress_modules | INFO - Quantizing model.layers.15.self_attn.v_proj using 128 samples\n",
            "2025-12-19T04:02:35.964909+0800 | compress | METRIC - time 0.89s\n",
            "2025-12-19T04:02:35.964909+0800 | compress | METRIC - error 1107.68\n",
            "2025-12-19T04:02:35.994184+0800 | compress | METRIC - GPU 0 | usage: 31.24% | total memory: 8 GB\n",
            "2025-12-19T04:02:35.995184+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:02:35.995184+0800 | compress_modules | INFO - Quantizing model.layers.15.self_attn.o_proj using 128 samples\n",
            "2025-12-19T04:02:36.875771+0800 | compress | METRIC - time 0.88s\n",
            "2025-12-19T04:02:36.875771+0800 | compress | METRIC - error 795.74\n",
            "2025-12-19T04:02:36.900299+0800 | compress | METRIC - GPU 0 | usage: 31.24% | total memory: 8 GB\n",
            "2025-12-19T04:02:36.901321+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T04:02:36.902398+0800 | compress_modules | INFO - Quantizing model.layers.15.mlp.gate_proj using 128 samples\n",
            "2025-12-19T04:02:37.794244+0800 | compress | METRIC - time 0.89s\n",
            "2025-12-19T04:02:37.795244+0800 | compress | METRIC - error 21490.45\n",
            "2025-12-19T04:02:37.820380+0800 | compress | METRIC - GPU 0 | usage: 31.24% | total memory: 8 GB\n",
            "2025-12-19T04:02:37.821377+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:02:37.821883+0800 | compress_modules | INFO - Quantizing model.layers.15.mlp.up_proj using 128 samples\n",
            "2025-12-19T04:02:38.691703+0800 | compress | METRIC - time 0.87s\n",
            "2025-12-19T04:02:38.691703+0800 | compress | METRIC - error 20347.40\n",
            "2025-12-19T04:02:38.709114+0800 | compress | METRIC - GPU 0 | usage: 31.24% | total memory: 8 GB\n",
            "2025-12-19T04:02:38.710111+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:02:38.710111+0800 | compress_modules | INFO - Quantizing model.layers.15.mlp.down_proj using 128 samples\n",
            "2025-12-19T04:02:44.075985+0800 | compress | METRIC - time 5.36s\n",
            "2025-12-19T04:02:44.075985+0800 | compress | METRIC - error 2580.12\n",
            "2025-12-19T04:02:44.089046+0800 | compress | METRIC - GPU 0 | usage: 35.00% | total memory: 8 GB\n",
            "2025-12-19T04:02:44.089046+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(16/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 76.92it/s]\n",
            "(17/29): Calibrating: 100%|██████████| 128/128 [00:06<00:00, 19.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:02:52.388503+0800 | compress_modules | INFO - Quantizing model.layers.16.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:02:53.509565+0800 | compress | METRIC - time 1.12s\n",
            "2025-12-19T04:02:53.510566+0800 | compress | METRIC - error 9642.27\n",
            "2025-12-19T04:02:53.532762+0800 | compress | METRIC - GPU 0 | usage: 31.09% | total memory: 8 GB\n",
            "2025-12-19T04:02:53.533760+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T04:02:53.534759+0800 | compress_modules | INFO - Quantizing model.layers.16.self_attn.k_proj using 128 samples\n",
            "2025-12-19T04:02:54.530194+0800 | compress | METRIC - time 1.00s\n",
            "2025-12-19T04:02:54.530194+0800 | compress | METRIC - error 1807.31\n",
            "2025-12-19T04:02:54.542340+0800 | compress | METRIC - GPU 0 | usage: 31.09% | total memory: 8 GB\n",
            "2025-12-19T04:02:54.543365+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:02:54.543365+0800 | compress_modules | INFO - Quantizing model.layers.16.self_attn.v_proj using 128 samples\n",
            "2025-12-19T04:02:55.406295+0800 | compress | METRIC - time 0.86s\n",
            "2025-12-19T04:02:55.407287+0800 | compress | METRIC - error 1410.14\n",
            "2025-12-19T04:02:55.428382+0800 | compress | METRIC - GPU 0 | usage: 31.09% | total memory: 8 GB\n",
            "2025-12-19T04:02:55.429403+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:02:55.430382+0800 | compress_modules | INFO - Quantizing model.layers.16.self_attn.o_proj using 128 samples\n",
            "2025-12-19T04:02:56.349250+0800 | compress | METRIC - time 0.92s\n",
            "2025-12-19T04:02:56.350261+0800 | compress | METRIC - error 631.76\n",
            "2025-12-19T04:02:56.373054+0800 | compress | METRIC - GPU 0 | usage: 31.09% | total memory: 8 GB\n",
            "2025-12-19T04:02:56.373054+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T04:02:56.374048+0800 | compress_modules | INFO - Quantizing model.layers.16.mlp.gate_proj using 128 samples\n",
            "2025-12-19T04:02:57.265052+0800 | compress | METRIC - time 0.89s\n",
            "2025-12-19T04:02:57.265052+0800 | compress | METRIC - error 24824.54\n",
            "2025-12-19T04:02:57.275448+0800 | compress | METRIC - GPU 0 | usage: 31.09% | total memory: 8 GB\n",
            "2025-12-19T04:02:57.275448+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:02:57.276448+0800 | compress_modules | INFO - Quantizing model.layers.16.mlp.up_proj using 128 samples\n",
            "2025-12-19T04:02:58.199747+0800 | compress | METRIC - time 0.92s\n",
            "2025-12-19T04:02:58.199747+0800 | compress | METRIC - error 24396.04\n",
            "2025-12-19T04:02:58.223586+0800 | compress | METRIC - GPU 0 | usage: 31.09% | total memory: 8 GB\n",
            "2025-12-19T04:02:58.224581+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:02:58.225579+0800 | compress_modules | INFO - Quantizing model.layers.16.mlp.down_proj using 128 samples\n",
            "2025-12-19T04:03:03.679774+0800 | compress | METRIC - time 5.45s\n",
            "2025-12-19T04:03:03.681280+0800 | compress | METRIC - error 2449.28\n",
            "2025-12-19T04:03:03.703417+0800 | compress | METRIC - GPU 0 | usage: 34.85% | total memory: 8 GB\n",
            "2025-12-19T04:03:03.704417+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(17/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 75.06it/s]\n",
            "(18/29): Calibrating: 100%|██████████| 128/128 [00:06<00:00, 19.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:03:12.078478+0800 | compress_modules | INFO - Quantizing model.layers.17.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:03:12.953830+0800 | compress | METRIC - time 0.87s\n",
            "2025-12-19T04:03:12.954832+0800 | compress | METRIC - error 8639.61\n",
            "2025-12-19T04:03:12.972662+0800 | compress | METRIC - GPU 0 | usage: 31.09% | total memory: 8 GB\n",
            "2025-12-19T04:03:12.973665+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T04:03:12.974662+0800 | compress_modules | INFO - Quantizing model.layers.17.self_attn.k_proj using 128 samples\n",
            "2025-12-19T04:03:13.829772+0800 | compress | METRIC - time 0.86s\n",
            "2025-12-19T04:03:13.829772+0800 | compress | METRIC - error 1060.22\n",
            "2025-12-19T04:03:13.841534+0800 | compress | METRIC - GPU 0 | usage: 31.09% | total memory: 8 GB\n",
            "2025-12-19T04:03:13.842065+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:03:13.843079+0800 | compress_modules | INFO - Quantizing model.layers.17.self_attn.v_proj using 128 samples\n",
            "2025-12-19T04:03:14.721567+0800 | compress | METRIC - time 0.88s\n",
            "2025-12-19T04:03:14.721567+0800 | compress | METRIC - error 1856.91\n",
            "2025-12-19T04:03:14.740163+0800 | compress | METRIC - GPU 0 | usage: 31.09% | total memory: 8 GB\n",
            "2025-12-19T04:03:14.741260+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:03:14.741260+0800 | compress_modules | INFO - Quantizing model.layers.17.self_attn.o_proj using 128 samples\n",
            "2025-12-19T04:03:15.594274+0800 | compress | METRIC - time 0.85s\n",
            "2025-12-19T04:03:15.594274+0800 | compress | METRIC - error 483.90\n",
            "2025-12-19T04:03:15.615225+0800 | compress | METRIC - GPU 0 | usage: 31.09% | total memory: 8 GB\n",
            "2025-12-19T04:03:15.616224+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T04:03:15.617222+0800 | compress_modules | INFO - Quantizing model.layers.17.mlp.gate_proj using 128 samples\n",
            "2025-12-19T04:03:16.525607+0800 | compress | METRIC - time 0.91s\n",
            "2025-12-19T04:03:16.526605+0800 | compress | METRIC - error 24731.27\n",
            "2025-12-19T04:03:16.548961+0800 | compress | METRIC - GPU 0 | usage: 31.09% | total memory: 8 GB\n",
            "2025-12-19T04:03:16.549489+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:03:16.550545+0800 | compress_modules | INFO - Quantizing model.layers.17.mlp.up_proj using 128 samples\n",
            "2025-12-19T04:03:17.368596+0800 | compress | METRIC - time 0.82s\n",
            "2025-12-19T04:03:17.368596+0800 | compress | METRIC - error 24610.09\n",
            "2025-12-19T04:03:17.388996+0800 | compress | METRIC - GPU 0 | usage: 31.09% | total memory: 8 GB\n",
            "2025-12-19T04:03:17.388996+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:03:17.389995+0800 | compress_modules | INFO - Quantizing model.layers.17.mlp.down_proj using 128 samples\n",
            "2025-12-19T04:03:22.601455+0800 | compress | METRIC - time 5.21s\n",
            "2025-12-19T04:03:22.601455+0800 | compress | METRIC - error 2543.87\n",
            "2025-12-19T04:03:22.619575+0800 | compress | METRIC - GPU 0 | usage: 38.61% | total memory: 8 GB\n",
            "2025-12-19T04:03:22.619575+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(18/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 76.61it/s]\n",
            "(19/29): Calibrating: 100%|██████████| 128/128 [00:06<00:00, 19.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:03:30.935827+0800 | compress_modules | INFO - Quantizing model.layers.18.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:03:31.785975+0800 | compress | METRIC - time 0.85s\n",
            "2025-12-19T04:03:31.785975+0800 | compress | METRIC - error 6996.57\n",
            "2025-12-19T04:03:31.804228+0800 | compress | METRIC - GPU 0 | usage: 30.99% | total memory: 8 GB\n",
            "2025-12-19T04:03:31.805334+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T04:03:31.806226+0800 | compress_modules | INFO - Quantizing model.layers.18.self_attn.k_proj using 128 samples\n",
            "2025-12-19T04:03:32.626439+0800 | compress | METRIC - time 0.82s\n",
            "2025-12-19T04:03:32.627439+0800 | compress | METRIC - error 1168.12\n",
            "2025-12-19T04:03:32.644587+0800 | compress | METRIC - GPU 0 | usage: 30.99% | total memory: 8 GB\n",
            "2025-12-19T04:03:32.645584+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:03:32.646583+0800 | compress_modules | INFO - Quantizing model.layers.18.self_attn.v_proj using 128 samples\n",
            "2025-12-19T04:03:33.453293+0800 | compress | METRIC - time 0.81s\n",
            "2025-12-19T04:03:33.454295+0800 | compress | METRIC - error 1180.66\n",
            "2025-12-19T04:03:33.466452+0800 | compress | METRIC - GPU 0 | usage: 30.99% | total memory: 8 GB\n",
            "2025-12-19T04:03:33.467450+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:03:33.467450+0800 | compress_modules | INFO - Quantizing model.layers.18.self_attn.o_proj using 128 samples\n",
            "2025-12-19T04:03:34.300537+0800 | compress | METRIC - time 0.83s\n",
            "2025-12-19T04:03:34.300537+0800 | compress | METRIC - error 767.75\n",
            "2025-12-19T04:03:34.321554+0800 | compress | METRIC - GPU 0 | usage: 30.99% | total memory: 8 GB\n",
            "2025-12-19T04:03:34.321554+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T04:03:34.322709+0800 | compress_modules | INFO - Quantizing model.layers.18.mlp.gate_proj using 128 samples\n",
            "2025-12-19T04:03:35.214242+0800 | compress | METRIC - time 0.89s\n",
            "2025-12-19T04:03:35.214242+0800 | compress | METRIC - error 26185.11\n",
            "2025-12-19T04:03:35.239265+0800 | compress | METRIC - GPU 0 | usage: 30.99% | total memory: 8 GB\n",
            "2025-12-19T04:03:35.240295+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:03:35.241266+0800 | compress_modules | INFO - Quantizing model.layers.18.mlp.up_proj using 128 samples\n",
            "2025-12-19T04:03:36.125282+0800 | compress | METRIC - time 0.88s\n",
            "2025-12-19T04:03:36.126283+0800 | compress | METRIC - error 25820.13\n",
            "2025-12-19T04:03:36.147711+0800 | compress | METRIC - GPU 0 | usage: 30.99% | total memory: 8 GB\n",
            "2025-12-19T04:03:36.148725+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:03:36.149724+0800 | compress_modules | INFO - Quantizing model.layers.18.mlp.down_proj using 128 samples\n",
            "2025-12-19T04:03:41.490935+0800 | compress | METRIC - time 5.34s\n",
            "2025-12-19T04:03:41.491459+0800 | compress | METRIC - error 3474.62\n",
            "2025-12-19T04:03:41.504041+0800 | compress | METRIC - GPU 0 | usage: 34.75% | total memory: 8 GB\n",
            "2025-12-19T04:03:41.505039+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(19/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 74.43it/s]\n",
            "(20/29): Calibrating: 100%|██████████| 128/128 [00:06<00:00, 19.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:03:49.836588+0800 | compress_modules | INFO - Quantizing model.layers.19.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:03:50.678077+0800 | compress | METRIC - time 0.84s\n",
            "2025-12-19T04:03:50.679077+0800 | compress | METRIC - error 9255.07\n",
            "2025-12-19T04:03:50.689710+0800 | compress | METRIC - GPU 0 | usage: 31.04% | total memory: 8 GB\n",
            "2025-12-19T04:03:50.691224+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T04:03:50.692229+0800 | compress_modules | INFO - Quantizing model.layers.19.self_attn.k_proj using 128 samples\n",
            "2025-12-19T04:03:51.506919+0800 | compress | METRIC - time 0.81s\n",
            "2025-12-19T04:03:51.506919+0800 | compress | METRIC - error 1223.66\n",
            "2025-12-19T04:03:51.527840+0800 | compress | METRIC - GPU 0 | usage: 31.04% | total memory: 8 GB\n",
            "2025-12-19T04:03:51.528869+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:03:51.529818+0800 | compress_modules | INFO - Quantizing model.layers.19.self_attn.v_proj using 128 samples\n",
            "2025-12-19T04:03:52.335351+0800 | compress | METRIC - time 0.81s\n",
            "2025-12-19T04:03:52.335954+0800 | compress | METRIC - error 2458.29\n",
            "2025-12-19T04:03:52.364385+0800 | compress | METRIC - GPU 0 | usage: 31.04% | total memory: 8 GB\n",
            "2025-12-19T04:03:52.365382+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:03:52.366385+0800 | compress_modules | INFO - Quantizing model.layers.19.self_attn.o_proj using 128 samples\n",
            "2025-12-19T04:03:53.174756+0800 | compress | METRIC - time 0.81s\n",
            "2025-12-19T04:03:53.174756+0800 | compress | METRIC - error 955.13\n",
            "2025-12-19T04:03:53.196373+0800 | compress | METRIC - GPU 0 | usage: 31.04% | total memory: 8 GB\n",
            "2025-12-19T04:03:53.197371+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T04:03:53.198371+0800 | compress_modules | INFO - Quantizing model.layers.19.mlp.gate_proj using 128 samples\n",
            "2025-12-19T04:03:54.079512+0800 | compress | METRIC - time 0.88s\n",
            "2025-12-19T04:03:54.079512+0800 | compress | METRIC - error 30840.75\n",
            "2025-12-19T04:03:54.090028+0800 | compress | METRIC - GPU 0 | usage: 31.04% | total memory: 8 GB\n",
            "2025-12-19T04:03:54.090028+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:03:54.091533+0800 | compress_modules | INFO - Quantizing model.layers.19.mlp.up_proj using 128 samples\n",
            "2025-12-19T04:03:54.957542+0800 | compress | METRIC - time 0.87s\n",
            "2025-12-19T04:03:54.958543+0800 | compress | METRIC - error 33142.53\n",
            "2025-12-19T04:03:54.981511+0800 | compress | METRIC - GPU 0 | usage: 31.04% | total memory: 8 GB\n",
            "2025-12-19T04:03:54.981511+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:03:54.982520+0800 | compress_modules | INFO - Quantizing model.layers.19.mlp.down_proj using 128 samples\n",
            "2025-12-19T04:04:00.136568+0800 | compress | METRIC - time 5.15s\n",
            "2025-12-19T04:04:00.137570+0800 | compress | METRIC - error 5410.31\n",
            "2025-12-19T04:04:00.157053+0800 | compress | METRIC - GPU 0 | usage: 38.56% | total memory: 8 GB\n",
            "2025-12-19T04:04:00.157053+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(20/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 76.48it/s]\n",
            "(21/29): Calibrating: 100%|██████████| 128/128 [00:06<00:00, 19.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:04:08.447591+0800 | compress_modules | INFO - Quantizing model.layers.20.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:04:09.347476+0800 | compress | METRIC - time 0.90s\n",
            "2025-12-19T04:04:09.348477+0800 | compress | METRIC - error 12134.48\n",
            "2025-12-19T04:04:09.372649+0800 | compress | METRIC - GPU 0 | usage: 31.24% | total memory: 8 GB\n",
            "2025-12-19T04:04:09.373653+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T04:04:09.374655+0800 | compress_modules | INFO - Quantizing model.layers.20.self_attn.k_proj using 128 samples\n",
            "2025-12-19T04:04:10.234669+0800 | compress | METRIC - time 0.86s\n",
            "2025-12-19T04:04:10.234669+0800 | compress | METRIC - error 1517.36\n",
            "2025-12-19T04:04:10.249223+0800 | compress | METRIC - GPU 0 | usage: 31.24% | total memory: 8 GB\n",
            "2025-12-19T04:04:10.250223+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:04:10.251222+0800 | compress_modules | INFO - Quantizing model.layers.20.self_attn.v_proj using 128 samples\n",
            "2025-12-19T04:04:11.091258+0800 | compress | METRIC - time 0.84s\n",
            "2025-12-19T04:04:11.091766+0800 | compress | METRIC - error 3626.41\n",
            "2025-12-19T04:04:11.110325+0800 | compress | METRIC - GPU 0 | usage: 31.24% | total memory: 8 GB\n",
            "2025-12-19T04:04:11.111334+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:04:11.112425+0800 | compress_modules | INFO - Quantizing model.layers.20.self_attn.o_proj using 128 samples\n",
            "2025-12-19T04:04:11.983098+0800 | compress | METRIC - time 0.87s\n",
            "2025-12-19T04:04:11.983098+0800 | compress | METRIC - error 1262.28\n",
            "2025-12-19T04:04:12.001482+0800 | compress | METRIC - GPU 0 | usage: 31.24% | total memory: 8 GB\n",
            "2025-12-19T04:04:12.001988+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T04:04:12.002995+0800 | compress_modules | INFO - Quantizing model.layers.20.mlp.gate_proj using 128 samples\n",
            "2025-12-19T04:04:12.885091+0800 | compress | METRIC - time 0.88s\n",
            "2025-12-19T04:04:12.885091+0800 | compress | METRIC - error 34573.96\n",
            "2025-12-19T04:04:12.902379+0800 | compress | METRIC - GPU 0 | usage: 31.24% | total memory: 8 GB\n",
            "2025-12-19T04:04:12.903373+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:04:12.904337+0800 | compress_modules | INFO - Quantizing model.layers.20.mlp.up_proj using 128 samples\n",
            "2025-12-19T04:04:13.751266+0800 | compress | METRIC - time 0.85s\n",
            "2025-12-19T04:04:13.751875+0800 | compress | METRIC - error 35464.05\n",
            "2025-12-19T04:04:13.768333+0800 | compress | METRIC - GPU 0 | usage: 31.24% | total memory: 8 GB\n",
            "2025-12-19T04:04:13.769308+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:04:13.769308+0800 | compress_modules | INFO - Quantizing model.layers.20.mlp.down_proj using 128 samples\n",
            "2025-12-19T04:04:18.977572+0800 | compress | METRIC - time 5.21s\n",
            "2025-12-19T04:04:18.978572+0800 | compress | METRIC - error 5109.10\n",
            "2025-12-19T04:04:18.998525+0800 | compress | METRIC - GPU 0 | usage: 35.00% | total memory: 8 GB\n",
            "2025-12-19T04:04:18.999520+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(21/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 75.91it/s]\n",
            "(22/29): Calibrating: 100%|██████████| 128/128 [00:06<00:00, 19.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:04:27.308988+0800 | compress_modules | INFO - Quantizing model.layers.21.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:04:28.142597+0800 | compress | METRIC - time 0.83s\n",
            "2025-12-19T04:04:28.143621+0800 | compress | METRIC - error 11721.79\n",
            "2025-12-19T04:04:28.155440+0800 | compress | METRIC - GPU 0 | usage: 31.04% | total memory: 8 GB\n",
            "2025-12-19T04:04:28.155440+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T04:04:28.156463+0800 | compress_modules | INFO - Quantizing model.layers.21.self_attn.k_proj using 128 samples\n",
            "2025-12-19T04:04:28.967410+0800 | compress | METRIC - time 0.81s\n",
            "2025-12-19T04:04:28.968411+0800 | compress | METRIC - error 1436.34\n",
            "2025-12-19T04:04:28.986246+0800 | compress | METRIC - GPU 0 | usage: 31.04% | total memory: 8 GB\n",
            "2025-12-19T04:04:28.987244+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:04:28.988243+0800 | compress_modules | INFO - Quantizing model.layers.21.self_attn.v_proj using 128 samples\n",
            "2025-12-19T04:04:29.839203+0800 | compress | METRIC - time 0.85s\n",
            "2025-12-19T04:04:29.840220+0800 | compress | METRIC - error 3118.75\n",
            "2025-12-19T04:04:29.875719+0800 | compress | METRIC - GPU 0 | usage: 31.04% | total memory: 8 GB\n",
            "2025-12-19T04:04:29.876718+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:04:29.877719+0800 | compress_modules | INFO - Quantizing model.layers.21.self_attn.o_proj using 128 samples\n",
            "2025-12-19T04:04:30.729253+0800 | compress | METRIC - time 0.85s\n",
            "2025-12-19T04:04:30.729253+0800 | compress | METRIC - error 690.21\n",
            "2025-12-19T04:04:30.751084+0800 | compress | METRIC - GPU 0 | usage: 31.04% | total memory: 8 GB\n",
            "2025-12-19T04:04:30.751084+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T04:04:30.752090+0800 | compress_modules | INFO - Quantizing model.layers.21.mlp.gate_proj using 128 samples\n",
            "2025-12-19T04:04:31.627065+0800 | compress | METRIC - time 0.87s\n",
            "2025-12-19T04:04:31.628568+0800 | compress | METRIC - error 48417.38\n",
            "2025-12-19T04:04:31.652097+0800 | compress | METRIC - GPU 0 | usage: 31.04% | total memory: 8 GB\n",
            "2025-12-19T04:04:31.653096+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:04:31.654095+0800 | compress_modules | INFO - Quantizing model.layers.21.mlp.up_proj using 128 samples\n",
            "2025-12-19T04:04:32.556172+0800 | compress | METRIC - time 0.90s\n",
            "2025-12-19T04:04:32.557172+0800 | compress | METRIC - error 48628.91\n",
            "2025-12-19T04:04:32.575190+0800 | compress | METRIC - GPU 0 | usage: 31.04% | total memory: 8 GB\n",
            "2025-12-19T04:04:32.576294+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:04:32.577189+0800 | compress_modules | INFO - Quantizing model.layers.21.mlp.down_proj using 128 samples\n",
            "2025-12-19T04:04:37.762861+0800 | compress | METRIC - time 5.19s\n",
            "2025-12-19T04:04:37.762861+0800 | compress | METRIC - error 7161.58\n",
            "2025-12-19T04:04:37.781056+0800 | compress | METRIC - GPU 0 | usage: 38.56% | total memory: 8 GB\n",
            "2025-12-19T04:04:37.782254+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(22/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 75.66it/s]\n",
            "(23/29): Calibrating: 100%|██████████| 128/128 [00:06<00:00, 19.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:04:46.164355+0800 | compress_modules | INFO - Quantizing model.layers.22.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:04:47.035568+0800 | compress | METRIC - time 0.87s\n",
            "2025-12-19T04:04:47.035568+0800 | compress | METRIC - error 10721.95\n",
            "2025-12-19T04:04:47.056437+0800 | compress | METRIC - GPU 0 | usage: 31.29% | total memory: 8 GB\n",
            "2025-12-19T04:04:47.057435+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T04:04:47.058436+0800 | compress_modules | INFO - Quantizing model.layers.22.self_attn.k_proj using 128 samples\n",
            "2025-12-19T04:04:47.875248+0800 | compress | METRIC - time 0.82s\n",
            "2025-12-19T04:04:47.876248+0800 | compress | METRIC - error 1612.44\n",
            "2025-12-19T04:04:47.897312+0800 | compress | METRIC - GPU 0 | usage: 31.29% | total memory: 8 GB\n",
            "2025-12-19T04:04:47.898346+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:04:47.899311+0800 | compress_modules | INFO - Quantizing model.layers.22.self_attn.v_proj using 128 samples\n",
            "2025-12-19T04:04:48.732238+0800 | compress | METRIC - time 0.83s\n",
            "2025-12-19T04:04:48.732238+0800 | compress | METRIC - error 3601.21\n",
            "2025-12-19T04:04:48.758654+0800 | compress | METRIC - GPU 0 | usage: 31.29% | total memory: 8 GB\n",
            "2025-12-19T04:04:48.759649+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:04:48.759649+0800 | compress_modules | INFO - Quantizing model.layers.22.self_attn.o_proj using 128 samples\n",
            "2025-12-19T04:04:49.666717+0800 | compress | METRIC - time 0.91s\n",
            "2025-12-19T04:04:49.666717+0800 | compress | METRIC - error 1344.63\n",
            "2025-12-19T04:04:49.686306+0800 | compress | METRIC - GPU 0 | usage: 31.29% | total memory: 8 GB\n",
            "2025-12-19T04:04:49.687303+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T04:04:49.688301+0800 | compress_modules | INFO - Quantizing model.layers.22.mlp.gate_proj using 128 samples\n",
            "2025-12-19T04:04:50.579501+0800 | compress | METRIC - time 0.89s\n",
            "2025-12-19T04:04:50.579501+0800 | compress | METRIC - error 56392.55\n",
            "2025-12-19T04:04:50.593186+0800 | compress | METRIC - GPU 0 | usage: 31.29% | total memory: 8 GB\n",
            "2025-12-19T04:04:50.594182+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:04:50.595182+0800 | compress_modules | INFO - Quantizing model.layers.22.mlp.up_proj using 128 samples\n",
            "2025-12-19T04:04:51.512345+0800 | compress | METRIC - time 0.92s\n",
            "2025-12-19T04:04:51.512345+0800 | compress | METRIC - error 55889.88\n",
            "2025-12-19T04:04:51.524412+0800 | compress | METRIC - GPU 0 | usage: 31.39% | total memory: 8 GB\n",
            "2025-12-19T04:04:51.525412+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:04:51.526411+0800 | compress_modules | INFO - Quantizing model.layers.22.mlp.down_proj using 128 samples\n",
            "2025-12-19T04:04:56.820211+0800 | compress | METRIC - time 5.29s\n",
            "2025-12-19T04:04:56.821229+0800 | compress | METRIC - error 9181.09\n",
            "2025-12-19T04:04:56.842859+0800 | compress | METRIC - GPU 0 | usage: 38.91% | total memory: 8 GB\n",
            "2025-12-19T04:04:56.843864+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(23/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 75.05it/s]\n",
            "(24/29): Calibrating: 100%|██████████| 128/128 [00:06<00:00, 19.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:05:05.174921+0800 | compress_modules | INFO - Quantizing model.layers.23.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:05:06.038409+0800 | compress | METRIC - time 0.86s\n",
            "2025-12-19T04:05:06.039393+0800 | compress | METRIC - error 14891.66\n",
            "2025-12-19T04:05:06.057993+0800 | compress | METRIC - GPU 0 | usage: 31.15% | total memory: 8 GB\n",
            "2025-12-19T04:05:06.059047+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T04:05:06.059047+0800 | compress_modules | INFO - Quantizing model.layers.23.self_attn.k_proj using 128 samples\n",
            "2025-12-19T04:05:06.904489+0800 | compress | METRIC - time 0.84s\n",
            "2025-12-19T04:05:06.905487+0800 | compress | METRIC - error 1742.02\n",
            "2025-12-19T04:05:06.915251+0800 | compress | METRIC - GPU 0 | usage: 31.15% | total memory: 8 GB\n",
            "2025-12-19T04:05:06.915251+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:05:06.916220+0800 | compress_modules | INFO - Quantizing model.layers.23.self_attn.v_proj using 128 samples\n",
            "2025-12-19T04:05:07.792457+0800 | compress | METRIC - time 0.88s\n",
            "2025-12-19T04:05:07.792457+0800 | compress | METRIC - error 4880.13\n",
            "2025-12-19T04:05:07.803074+0800 | compress | METRIC - GPU 0 | usage: 31.15% | total memory: 8 GB\n",
            "2025-12-19T04:05:07.804096+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:05:07.805074+0800 | compress_modules | INFO - Quantizing model.layers.23.self_attn.o_proj using 128 samples\n",
            "2025-12-19T04:05:08.734034+0800 | compress | METRIC - time 0.93s\n",
            "2025-12-19T04:05:08.735034+0800 | compress | METRIC - error 2580.76\n",
            "2025-12-19T04:05:08.748604+0800 | compress | METRIC - GPU 0 | usage: 31.15% | total memory: 8 GB\n",
            "2025-12-19T04:05:08.749603+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T04:05:08.749603+0800 | compress_modules | INFO - Quantizing model.layers.23.mlp.gate_proj using 128 samples\n",
            "2025-12-19T04:05:09.679224+0800 | compress | METRIC - time 0.93s\n",
            "2025-12-19T04:05:09.680224+0800 | compress | METRIC - error 54977.34\n",
            "2025-12-19T04:05:09.697278+0800 | compress | METRIC - GPU 0 | usage: 31.15% | total memory: 8 GB\n",
            "2025-12-19T04:05:09.698299+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:05:09.699279+0800 | compress_modules | INFO - Quantizing model.layers.23.mlp.up_proj using 128 samples\n",
            "2025-12-19T04:05:10.619173+0800 | compress | METRIC - time 0.92s\n",
            "2025-12-19T04:05:10.620151+0800 | compress | METRIC - error 57378.86\n",
            "2025-12-19T04:05:10.632765+0800 | compress | METRIC - GPU 0 | usage: 31.15% | total memory: 8 GB\n",
            "2025-12-19T04:05:10.633770+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:05:10.634770+0800 | compress_modules | INFO - Quantizing model.layers.23.mlp.down_proj using 128 samples\n",
            "2025-12-19T04:05:16.062275+0800 | compress | METRIC - time 5.43s\n",
            "2025-12-19T04:05:16.063297+0800 | compress | METRIC - error 9582.54\n",
            "2025-12-19T04:05:16.079863+0800 | compress | METRIC - GPU 0 | usage: 38.67% | total memory: 8 GB\n",
            "2025-12-19T04:05:16.081419+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(24/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 75.75it/s]\n",
            "(25/29): Calibrating: 100%|██████████| 128/128 [00:06<00:00, 19.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:05:24.388375+0800 | compress_modules | INFO - Quantizing model.layers.24.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:05:25.233851+0800 | compress | METRIC - time 0.84s\n",
            "2025-12-19T04:05:25.234875+0800 | compress | METRIC - error 13109.39\n",
            "2025-12-19T04:05:25.256311+0800 | compress | METRIC - GPU 0 | usage: 31.20% | total memory: 8 GB\n",
            "2025-12-19T04:05:25.257308+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T04:05:25.258200+0800 | compress_modules | INFO - Quantizing model.layers.24.self_attn.k_proj using 128 samples\n",
            "2025-12-19T04:05:26.054166+0800 | compress | METRIC - time 0.80s\n",
            "2025-12-19T04:05:26.055183+0800 | compress | METRIC - error 1736.88\n",
            "2025-12-19T04:05:26.079410+0800 | compress | METRIC - GPU 0 | usage: 31.20% | total memory: 8 GB\n",
            "2025-12-19T04:05:26.080409+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:05:26.080409+0800 | compress_modules | INFO - Quantizing model.layers.24.self_attn.v_proj using 128 samples\n",
            "2025-12-19T04:05:26.901314+0800 | compress | METRIC - time 0.82s\n",
            "2025-12-19T04:05:26.902457+0800 | compress | METRIC - error 7275.52\n",
            "2025-12-19T04:05:26.916552+0800 | compress | METRIC - GPU 0 | usage: 31.20% | total memory: 8 GB\n",
            "2025-12-19T04:05:26.917552+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:05:26.917552+0800 | compress_modules | INFO - Quantizing model.layers.24.self_attn.o_proj using 128 samples\n",
            "2025-12-19T04:05:27.762132+0800 | compress | METRIC - time 0.84s\n",
            "2025-12-19T04:05:27.763134+0800 | compress | METRIC - error 2860.34\n",
            "2025-12-19T04:05:27.786389+0800 | compress | METRIC - GPU 0 | usage: 31.20% | total memory: 8 GB\n",
            "2025-12-19T04:05:27.787386+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T04:05:27.788432+0800 | compress_modules | INFO - Quantizing model.layers.24.mlp.gate_proj using 128 samples\n",
            "2025-12-19T04:05:28.683641+0800 | compress | METRIC - time 0.89s\n",
            "2025-12-19T04:05:28.684640+0800 | compress | METRIC - error 50788.84\n",
            "2025-12-19T04:05:28.701279+0800 | compress | METRIC - GPU 0 | usage: 31.20% | total memory: 8 GB\n",
            "2025-12-19T04:05:28.702316+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:05:28.703317+0800 | compress_modules | INFO - Quantizing model.layers.24.mlp.up_proj using 128 samples\n",
            "2025-12-19T04:05:29.573187+0800 | compress | METRIC - time 0.87s\n",
            "2025-12-19T04:05:29.574230+0800 | compress | METRIC - error 54602.40\n",
            "2025-12-19T04:05:29.592313+0800 | compress | METRIC - GPU 0 | usage: 31.20% | total memory: 8 GB\n",
            "2025-12-19T04:05:29.593310+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:05:29.594315+0800 | compress_modules | INFO - Quantizing model.layers.24.mlp.down_proj using 128 samples\n",
            "2025-12-19T04:05:34.874972+0800 | compress | METRIC - time 5.28s\n",
            "2025-12-19T04:05:34.874972+0800 | compress | METRIC - error 10101.00\n",
            "2025-12-19T04:05:34.889911+0800 | compress | METRIC - GPU 0 | usage: 38.72% | total memory: 8 GB\n",
            "2025-12-19T04:05:34.891514+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(25/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 75.71it/s]\n",
            "(26/29): Calibrating: 100%|██████████| 128/128 [00:06<00:00, 19.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:05:43.255461+0800 | compress_modules | INFO - Quantizing model.layers.25.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:05:44.105219+0800 | compress | METRIC - time 0.85s\n",
            "2025-12-19T04:05:44.106218+0800 | compress | METRIC - error 15047.20\n",
            "2025-12-19T04:05:44.119403+0800 | compress | METRIC - GPU 0 | usage: 31.10% | total memory: 8 GB\n",
            "2025-12-19T04:05:44.120403+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T04:05:44.121401+0800 | compress_modules | INFO - Quantizing model.layers.25.self_attn.k_proj using 128 samples\n",
            "2025-12-19T04:05:44.908339+0800 | compress | METRIC - time 0.79s\n",
            "2025-12-19T04:05:44.909341+0800 | compress | METRIC - error 1569.79\n",
            "2025-12-19T04:05:44.931126+0800 | compress | METRIC - GPU 0 | usage: 31.10% | total memory: 8 GB\n",
            "2025-12-19T04:05:44.931126+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:05:44.932132+0800 | compress_modules | INFO - Quantizing model.layers.25.self_attn.v_proj using 128 samples\n",
            "2025-12-19T04:05:45.789765+0800 | compress | METRIC - time 0.86s\n",
            "2025-12-19T04:05:45.791360+0800 | compress | METRIC - error 7151.25\n",
            "2025-12-19T04:05:45.812511+0800 | compress | METRIC - GPU 0 | usage: 31.10% | total memory: 8 GB\n",
            "2025-12-19T04:05:45.813049+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:05:45.813917+0800 | compress_modules | INFO - Quantizing model.layers.25.self_attn.o_proj using 128 samples\n",
            "2025-12-19T04:05:46.666374+0800 | compress | METRIC - time 0.85s\n",
            "2025-12-19T04:05:46.666374+0800 | compress | METRIC - error 2506.50\n",
            "2025-12-19T04:05:46.683537+0800 | compress | METRIC - GPU 0 | usage: 31.10% | total memory: 8 GB\n",
            "2025-12-19T04:05:46.684181+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T04:05:46.684767+0800 | compress_modules | INFO - Quantizing model.layers.25.mlp.gate_proj using 128 samples\n",
            "2025-12-19T04:05:47.550106+0800 | compress | METRIC - time 0.86s\n",
            "2025-12-19T04:05:47.550106+0800 | compress | METRIC - error 52315.64\n",
            "2025-12-19T04:05:47.570449+0800 | compress | METRIC - GPU 0 | usage: 31.10% | total memory: 8 GB\n",
            "2025-12-19T04:05:47.571449+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:05:47.571449+0800 | compress_modules | INFO - Quantizing model.layers.25.mlp.up_proj using 128 samples\n",
            "2025-12-19T04:05:48.442160+0800 | compress | METRIC - time 0.87s\n",
            "2025-12-19T04:05:48.443162+0800 | compress | METRIC - error 60585.73\n",
            "2025-12-19T04:05:48.458259+0800 | compress | METRIC - GPU 0 | usage: 31.10% | total memory: 8 GB\n",
            "2025-12-19T04:05:48.459361+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:05:48.460258+0800 | compress_modules | INFO - Quantizing model.layers.25.mlp.down_proj using 128 samples\n",
            "2025-12-19T04:05:53.677632+0800 | compress | METRIC - time 5.22s\n",
            "2025-12-19T04:05:53.678631+0800 | compress | METRIC - error 14019.94\n",
            "2025-12-19T04:05:53.699328+0800 | compress | METRIC - GPU 0 | usage: 34.86% | total memory: 8 GB\n",
            "2025-12-19T04:05:53.700328+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(26/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 76.15it/s]\n",
            "(27/29): Calibrating: 100%|██████████| 128/128 [00:06<00:00, 19.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:06:02.007175+0800 | compress_modules | INFO - Quantizing model.layers.26.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:06:02.862759+0800 | compress | METRIC - time 0.85s\n",
            "2025-12-19T04:06:02.862759+0800 | compress | METRIC - error 15962.14\n",
            "2025-12-19T04:06:02.888358+0800 | compress | METRIC - GPU 0 | usage: 31.15% | total memory: 8 GB\n",
            "2025-12-19T04:06:02.889329+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T04:06:02.890328+0800 | compress_modules | INFO - Quantizing model.layers.26.self_attn.k_proj using 128 samples\n",
            "2025-12-19T04:06:03.714147+0800 | compress | METRIC - time 0.82s\n",
            "2025-12-19T04:06:03.715148+0800 | compress | METRIC - error 1974.02\n",
            "2025-12-19T04:06:03.735914+0800 | compress | METRIC - GPU 0 | usage: 31.15% | total memory: 8 GB\n",
            "2025-12-19T04:06:03.736916+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:06:03.737963+0800 | compress_modules | INFO - Quantizing model.layers.26.self_attn.v_proj using 128 samples\n",
            "2025-12-19T04:06:04.616430+0800 | compress | METRIC - time 0.88s\n",
            "2025-12-19T04:06:04.616430+0800 | compress | METRIC - error 11667.66\n",
            "2025-12-19T04:06:04.638358+0800 | compress | METRIC - GPU 0 | usage: 31.15% | total memory: 8 GB\n",
            "2025-12-19T04:06:04.639356+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:06:04.639356+0800 | compress_modules | INFO - Quantizing model.layers.26.self_attn.o_proj using 128 samples\n",
            "2025-12-19T04:06:05.518354+0800 | compress | METRIC - time 0.88s\n",
            "2025-12-19T04:06:05.519354+0800 | compress | METRIC - error 4082.68\n",
            "2025-12-19T04:06:05.544526+0800 | compress | METRIC - GPU 0 | usage: 31.15% | total memory: 8 GB\n",
            "2025-12-19T04:06:05.545621+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T04:06:05.546524+0800 | compress_modules | INFO - Quantizing model.layers.26.mlp.gate_proj using 128 samples\n",
            "2025-12-19T04:06:06.469524+0800 | compress | METRIC - time 0.92s\n",
            "2025-12-19T04:06:06.470520+0800 | compress | METRIC - error 46346.91\n",
            "2025-12-19T04:06:06.489701+0800 | compress | METRIC - GPU 0 | usage: 31.15% | total memory: 8 GB\n",
            "2025-12-19T04:06:06.489701+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:06:06.491206+0800 | compress_modules | INFO - Quantizing model.layers.26.mlp.up_proj using 128 samples\n",
            "2025-12-19T04:06:07.431236+0800 | compress | METRIC - time 0.94s\n",
            "2025-12-19T04:06:07.431740+0800 | compress | METRIC - error 55774.52\n",
            "2025-12-19T04:06:07.454321+0800 | compress | METRIC - GPU 0 | usage: 31.15% | total memory: 8 GB\n",
            "2025-12-19T04:06:07.455321+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:06:07.455321+0800 | compress_modules | INFO - Quantizing model.layers.26.mlp.down_proj using 128 samples\n",
            "2025-12-19T04:06:12.823144+0800 | compress | METRIC - time 5.37s\n",
            "2025-12-19T04:06:12.824222+0800 | compress | METRIC - error 29406.58\n",
            "2025-12-19T04:06:12.843619+0800 | compress | METRIC - GPU 0 | usage: 38.67% | total memory: 8 GB\n",
            "2025-12-19T04:06:12.843619+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(27/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 74.69it/s]\n",
            "(28/29): Calibrating: 100%|██████████| 128/128 [00:06<00:00, 19.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:06:21.244158+0800 | compress_modules | INFO - Quantizing model.layers.27.self_attn.q_proj using 128 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:06:22.218875+0800 | compress | METRIC - time 0.97s\n",
            "2025-12-19T04:06:22.218875+0800 | compress | METRIC - error 15532.10\n",
            "2025-12-19T04:06:22.233347+0800 | compress | METRIC - GPU 0 | usage: 31.34% | total memory: 8 GB\n",
            "2025-12-19T04:06:22.233347+0800 | compress | METRIC - Compressed module size: 4.77696 MB\n",
            "2025-12-19T04:06:22.235237+0800 | compress_modules | INFO - Quantizing model.layers.27.self_attn.k_proj using 128 samples\n",
            "2025-12-19T04:06:23.173135+0800 | compress | METRIC - time 0.94s\n",
            "2025-12-19T04:06:23.174106+0800 | compress | METRIC - error 1639.69\n",
            "2025-12-19T04:06:23.234549+0800 | compress | METRIC - GPU 0 | usage: 31.34% | total memory: 8 GB\n",
            "2025-12-19T04:06:23.235572+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:06:23.236548+0800 | compress_modules | INFO - Quantizing model.layers.27.self_attn.v_proj using 128 samples\n",
            "2025-12-19T04:06:24.210489+0800 | compress | METRIC - time 0.97s\n",
            "2025-12-19T04:06:24.210489+0800 | compress | METRIC - error 11918.36\n",
            "2025-12-19T04:06:24.227109+0800 | compress | METRIC - GPU 0 | usage: 31.34% | total memory: 8 GB\n",
            "2025-12-19T04:06:24.228126+0800 | compress | METRIC - Compressed module size: 0.79616 MB\n",
            "2025-12-19T04:06:24.228126+0800 | compress_modules | INFO - Quantizing model.layers.27.self_attn.o_proj using 128 samples\n",
            "2025-12-19T04:06:25.117930+0800 | compress | METRIC - time 0.89s\n",
            "2025-12-19T04:06:25.117930+0800 | compress | METRIC - error 8658.46\n",
            "2025-12-19T04:06:25.144394+0800 | compress | METRIC - GPU 0 | usage: 31.34% | total memory: 8 GB\n",
            "2025-12-19T04:06:25.145425+0800 | compress | METRIC - Compressed module size: 4.773888 MB\n",
            "2025-12-19T04:06:25.146426+0800 | compress_modules | INFO - Quantizing model.layers.27.mlp.gate_proj using 128 samples\n",
            "2025-12-19T04:06:26.003107+0800 | compress | METRIC - time 0.86s\n",
            "2025-12-19T04:06:26.003107+0800 | compress | METRIC - error 67178.08\n",
            "2025-12-19T04:06:26.025615+0800 | compress | METRIC - GPU 0 | usage: 31.34% | total memory: 8 GB\n",
            "2025-12-19T04:06:26.037133+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:06:26.038132+0800 | compress_modules | INFO - Quantizing model.layers.27.mlp.up_proj using 128 samples\n",
            "2025-12-19T04:06:26.912412+0800 | compress | METRIC - time 0.87s\n",
            "2025-12-19T04:06:26.913415+0800 | compress | METRIC - error 69444.49\n",
            "2025-12-19T04:06:26.929075+0800 | compress | METRIC - GPU 0 | usage: 31.34% | total memory: 8 GB\n",
            "2025-12-19T04:06:26.930100+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n",
            "2025-12-19T04:06:26.931074+0800 | compress_modules | INFO - Quantizing model.layers.27.mlp.down_proj using 128 samples\n",
            "2025-12-19T04:06:32.576358+0800 | compress | METRIC - time 5.65s\n",
            "2025-12-19T04:06:32.576358+0800 | compress | METRIC - error 36385.44\n",
            "2025-12-19T04:06:32.596258+0800 | compress | METRIC - GPU 0 | usage: 35.10% | total memory: 8 GB\n",
            "2025-12-19T04:06:32.597269+0800 | compress | METRIC - Compressed module size: 27.84768 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "(28/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 75.32it/s]\n",
            "(29/29): Calibrating: 100%|██████████| 128/128 [00:00<00:00, 757.74it/s]\n",
            "(29/29): Propagating: 100%|██████████| 128/128 [00:00<00:00, 854.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:06:34.668162+0800 | finalize | INFO - Compression lifecycle finalized for 1 modifiers\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:06:34.722376+0800 | get_model_compressor | INFO - skip_sparsity_compression_stats set to True. Skipping sparsity compression statistic calculations. No sparsity compressor will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Compressing model: 196it [00:03, 52.05it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'models/qwen2.5-1.5b-instruct-gptq-llmc'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 使用 llmcompressor 对 Qwen2.5-7B-Instruct 做 GPTQ 量化\n",
        "\n",
        "# 量化后模型输出目录（可根据需要调整路径）\n",
        "gptq_out_dir = \"models/qwen2.5-1.5b-instruct-gptq-llmc\"\n",
        "\n",
        "gptq_recipe = [\n",
        "    GPTQModifier(\n",
        "        scheme=\"W4A16\",      # 权重 4bit，激活保持 16bit\n",
        "        targets=\"Linear\",    # 只量化线性层\n",
        "        ignore=[\"lm_head\"],  # 通常不量化输出头\n",
        "    ),\n",
        "]\n",
        "\n",
        "oneshot(\n",
        "    model=base_model_id,\n",
        "    dataset=\"open_platypus\",      # 内置公开数据集，方便快速演示\n",
        "    recipe=gptq_recipe,\n",
        "    output_dir=gptq_out_dir,\n",
        "    max_seq_length=2048,\n",
        "    num_calibration_samples=128,   # 为了速度，这里只取少量校准样本\n",
        ")\n",
        "\n",
        "gptq_out_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer you are loading from 'models/qwen2.5-1.5b-instruct-gptq-llmc' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n",
            "Compressing model: 196it [00:00, 1131.44it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('<|endoftext|>', '<|im_end|>', 151643, 151645)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 加载 GPTQ 量化后的检查点做推理\n",
        "\n",
        "gptq_tokenizer = AutoTokenizer.from_pretrained(gptq_out_dir, trust_remote_code=True)\n",
        "if gptq_tokenizer.pad_token_id is None:\n",
        "    gptq_tokenizer.pad_token = gptq_tokenizer.eos_token\n",
        "\n",
        "gptq_model = AutoModelForCausalLM.from_pretrained(\n",
        "    gptq_out_dir,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16,\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "gptq_model.eval()\n",
        "\n",
        "gptq_tokenizer.pad_token, gptq_tokenizer.eos_token, gptq_tokenizer.pad_token_id, gptq_tokenizer.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPTQ q_proj layer type: <class 'compressed_tensors.linear.compressed_linear.CompressedLinear'>\n",
            "GPTQ quantization_config: CompressedTensorsConfig {\n",
            "  \"config_groups\": {\n",
            "    \"group_0\": {\n",
            "      \"format\": \"pack-quantized\",\n",
            "      \"input_activations\": null,\n",
            "      \"output_activations\": null,\n",
            "      \"targets\": [\n",
            "        \"Linear\"\n",
            "      ],\n",
            "      \"weights\": {\n",
            "        \"actorder\": \"static\",\n",
            "        \"block_structure\": null,\n",
            "        \"dynamic\": false,\n",
            "        \"group_size\": 128,\n",
            "        \"num_bits\": 4,\n",
            "        \"observer\": \"minmax\",\n",
            "        \"observer_kwargs\": {},\n",
            "        \"scale_dtype\": null,\n",
            "        \"strategy\": \"group\",\n",
            "        \"symmetric\": true,\n",
            "        \"type\": \"int\",\n",
            "        \"zp_dtype\": null\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  \"format\": \"pack-quantized\",\n",
            "  \"global_compression_ratio\": null,\n",
            "  \"ignore\": [\n",
            "    \"lm_head\"\n",
            "  ],\n",
            "  \"kv_cache_scheme\": null,\n",
            "  \"quantization_status\": \"compressed\"\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 检查 GPTQ 量化是否生效：查看第 0 层 self_attn.q_proj 的类型和配置\n",
        "layer = gptq_model.model.layers[0].self_attn.q_proj\n",
        "print(\"GPTQ q_proj layer type:\", type(layer))\n",
        "print(\"GPTQ quantization_config:\", getattr(gptq_model.config, \"quantization_config\", None))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GPTQ 量化模型对话推理示例"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[GPTQ] Q: 用两三句话解释一下什么是量子计算？\n",
            "A: 量子计算是利用量子位（qubits）代替经典比特进行信息处理的一种计算方式。它利用量子叠加、纠缠等特性来实现超越传统计算机的并行处理能力，可以高效地解决某些特定问题。通过使用量子比特，量子计算机可以在短时间内完成复杂的数学运算和模拟物理系统，对于密码破解、优化算法等领域具有巨大潜力。尽管目前的技术还处于发展阶段，但未来有望成为一种强大的计算工具。\n",
            "------------------------------------------------------------\n",
            "[GPTQ] Q: Give me a brief introduction to large language models in English.\n",
            "A: Large Language Models (LLMs) are advanced artificial intelligence systems that can understand and generate human-like text across various domains, including natural language processing tasks such as translation, summarization, question-answering, and more.\n",
            "\n",
            "These models use deep learning algorithms, which enable them to learn from vast amounts of data and improve their performance over time. The most prominent example is the GPT (Generative Pretrained Transformer), developed by OpenAI, which has been used for many applications like language generation, image description, and even creative writing.\n",
            "\n",
            "One key feature of LLMs is their ability to handle unstructured or semi-structured data, making them versatile tools for information retrieval, content creation, and dialogue systems.\n",
            "\n",
            "However, there are ongoing debates about how these models might be used responsibly, especially regarding ethical considerations in the potential misuse of autonomous decision-making capabilities. As with any powerful technology, ensuring responsible development and deployment is critical for society to benefit while mitigating risks.\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "GPTQ_TEST_QUERIES = [\n",
        "    \"用两三句话解释一下什么是量子计算？\",\n",
        "    \"Give me a brief introduction to large language models in English.\",\n",
        "]\n",
        "\n",
        "@torch.no_grad()\n",
        "def gptq_chat(question: str) -> str:\n",
        "    msgs = [\n",
        "        {\"role\": \"system\", \"content\": \"你是一名 AI 助手，回答准确、简洁。\"},\n",
        "        {\"role\": \"user\", \"content\": question},\n",
        "    ]\n",
        "    input_ids = gptq_tokenizer.apply_chat_template(\n",
        "        msgs,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=True,\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(gptq_model.device)\n",
        "\n",
        "    gen_ids = gptq_model.generate(\n",
        "        input_ids=input_ids,\n",
        "        max_new_tokens=256,\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        repetition_penalty=1.1,\n",
        "        eos_token_id=gptq_tokenizer.eos_token_id,\n",
        "        pad_token_id=gptq_tokenizer.pad_token_id,\n",
        "    )\n",
        "    out_ids = gen_ids[0, input_ids.shape[-1]:]\n",
        "    return gptq_tokenizer.decode(out_ids, skip_special_tokens=True).strip()\n",
        "\n",
        "for q in GPTQ_TEST_QUERIES:\n",
        "    ans = gptq_chat(q)\n",
        "    print(f\"[GPTQ] Q: {q}\\nA: {ans}\\n\" + \"-\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 释放 GPTQ 量化模型占用的显存\n",
        "del gptq_model\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 二、使用 llmcompressor + AWQ 对 Qwen2.5-7B-Instruct 进行量化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40c6c9d76a22406aad56367952331385",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizing:   0%|          | 0/24926 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T04:08:32.087210+0800 | reset | INFO - Compression lifecycle reset\n",
            "2025-12-19T04:08:32.099173+0800 | from_modifiers | INFO - Creating recipe from modifiers\n",
            "2025-12-19T04:08:32.139239+0800 | on_initialize | INFO - No AWQModifier.mappings provided, inferring from model...\n",
            "2025-12-19T04:08:32.146092+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.0.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.147094+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.1.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.148103+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.2.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.148728+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.3.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.149877+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.4.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.149877+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.5.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.150840+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.6.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.151862+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.7.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.152868+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.8.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.152868+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.9.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.153880+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.10.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.154866+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.11.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.154866+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.12.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.155869+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.13.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.155869+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.14.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.156862+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.15.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.156862+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.16.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.158502+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.17.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.158502+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.18.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.159633+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.19.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.159633+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.20.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.160632+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.21.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.161509+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.22.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.162509+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.23.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.162509+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.24.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.163643+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.25.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.164639+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.26.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.164639+0800 | _set_resolved_mappings | WARNING - skipping AWQ for model.layers.27.self_attn.v_proj for mapping AWQMapping(smooth_layer='re:.*v_proj$', balance_layers=['re:.*o_proj$']) because found incompatible balance layers\n",
            "2025-12-19T04:08:32.174455+0800 | initialize | INFO - Compression lifecycle initialized for 1 modifiers\n",
            "2025-12-19T04:08:32.175474+0800 | IndependentPipeline | INFO - Inferred `SequentialPipeline` for `AWQModifier`\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Preparing cache: 100%|██████████| 128/128 [00:00<00:00, 665.58it/s]\n",
            "(1/29): Calibrating: 100%|██████████| 128/128 [00:28<00:00,  4.53it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [12:56<00:00, 258.98s/it]\n",
            "(1/29): Propagating: 100%|██████████| 128/128 [00:30<00:00,  4.23it/s]\n",
            "(2/29): Calibrating: 100%|██████████| 128/128 [00:24<00:00,  5.19it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [13:35<00:00, 271.83s/it]\n",
            "(2/29): Propagating: 100%|██████████| 128/128 [00:47<00:00,  2.69it/s]\n",
            "(3/29): Calibrating: 100%|██████████| 128/128 [00:34<00:00,  3.67it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [17:54<00:00, 358.33s/it]\n",
            "(3/29): Propagating: 100%|██████████| 128/128 [00:33<00:00,  3.87it/s]\n",
            "(4/29): Calibrating: 100%|██████████| 128/128 [00:31<00:00,  4.12it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [13:25<00:00, 268.42s/it]\n",
            "(4/29): Propagating: 100%|██████████| 128/128 [00:41<00:00,  3.11it/s]\n",
            "(5/29): Calibrating: 100%|██████████| 128/128 [00:22<00:00,  5.59it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [11:18<00:00, 226.02s/it]\n",
            "(5/29): Propagating: 100%|██████████| 128/128 [00:25<00:00,  5.05it/s]\n",
            "(6/29): Calibrating: 100%|██████████| 128/128 [00:22<00:00,  5.71it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [09:25<00:00, 188.41s/it]\n",
            "(6/29): Propagating: 100%|██████████| 128/128 [00:29<00:00,  4.36it/s]\n",
            "(7/29): Calibrating: 100%|██████████| 128/128 [00:22<00:00,  5.62it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [11:47<00:00, 235.89s/it]\n",
            "(7/29): Propagating: 100%|██████████| 128/128 [00:14<00:00,  8.96it/s]\n",
            "(8/29): Calibrating: 100%|██████████| 128/128 [00:21<00:00,  5.86it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [09:21<00:00, 187.13s/it]\n",
            "(8/29): Propagating: 100%|██████████| 128/128 [00:20<00:00,  6.34it/s]\n",
            "(9/29): Calibrating: 100%|██████████| 128/128 [00:24<00:00,  5.14it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [11:53<00:00, 237.83s/it]\n",
            "(9/29): Propagating: 100%|██████████| 128/128 [00:16<00:00,  7.86it/s]\n",
            "(10/29): Calibrating: 100%|██████████| 128/128 [00:22<00:00,  5.79it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [09:01<00:00, 180.62s/it]\n",
            "(10/29): Propagating: 100%|██████████| 128/128 [00:20<00:00,  6.29it/s]\n",
            "(11/29): Calibrating: 100%|██████████| 128/128 [00:22<00:00,  5.75it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [11:15<00:00, 225.25s/it]\n",
            "(11/29): Propagating: 100%|██████████| 128/128 [00:14<00:00,  8.60it/s]\n",
            "(12/29): Calibrating: 100%|██████████| 128/128 [00:22<00:00,  5.81it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [09:14<00:00, 184.80s/it]\n",
            "(12/29): Propagating: 100%|██████████| 128/128 [00:22<00:00,  5.73it/s]\n",
            "(13/29): Calibrating: 100%|██████████| 128/128 [00:22<00:00,  5.63it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [11:10<00:00, 223.41s/it]\n",
            "(13/29): Propagating: 100%|██████████| 128/128 [00:14<00:00,  8.73it/s]\n",
            "(14/29): Calibrating: 100%|██████████| 128/128 [00:21<00:00,  5.99it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [08:52<00:00, 177.58s/it]\n",
            "(14/29): Propagating: 100%|██████████| 128/128 [00:18<00:00,  6.88it/s]\n",
            "(15/29): Calibrating: 100%|██████████| 128/128 [00:21<00:00,  5.97it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [11:03<00:00, 221.31s/it]\n",
            "(15/29): Propagating: 100%|██████████| 128/128 [00:14<00:00,  8.86it/s]\n",
            "(16/29): Calibrating: 100%|██████████| 128/128 [00:21<00:00,  5.86it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [09:08<00:00, 182.82s/it]\n",
            "(16/29): Propagating: 100%|██████████| 128/128 [00:19<00:00,  6.62it/s]\n",
            "(17/29): Calibrating: 100%|██████████| 128/128 [00:21<00:00,  5.85it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [11:03<00:00, 221.16s/it]\n",
            "(17/29): Propagating: 100%|██████████| 128/128 [00:14<00:00,  9.05it/s]\n",
            "(18/29): Calibrating: 100%|██████████| 128/128 [00:21<00:00,  5.97it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [08:58<00:00, 179.41s/it]\n",
            "(18/29): Propagating: 100%|██████████| 128/128 [00:18<00:00,  6.90it/s]\n",
            "(19/29): Calibrating: 100%|██████████| 128/128 [00:21<00:00,  5.84it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [11:03<00:00, 221.32s/it]\n",
            "(19/29): Propagating: 100%|██████████| 128/128 [00:14<00:00,  8.76it/s]\n",
            "(20/29): Calibrating: 100%|██████████| 128/128 [00:23<00:00,  5.49it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [09:22<00:00, 187.64s/it]\n",
            "(20/29): Propagating: 100%|██████████| 128/128 [00:19<00:00,  6.56it/s]\n",
            "(21/29): Calibrating: 100%|██████████| 128/128 [00:21<00:00,  5.93it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [11:06<00:00, 222.27s/it]\n",
            "(21/29): Propagating: 100%|██████████| 128/128 [00:14<00:00,  8.67it/s]\n",
            "(22/29): Calibrating: 100%|██████████| 128/128 [00:20<00:00,  6.10it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [08:54<00:00, 178.00s/it]\n",
            "(22/29): Propagating: 100%|██████████| 128/128 [00:17<00:00,  7.27it/s]\n",
            "(23/29): Calibrating: 100%|██████████| 128/128 [00:21<00:00,  5.91it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [10:57<00:00, 219.13s/it]\n",
            "(23/29): Propagating: 100%|██████████| 128/128 [00:14<00:00,  8.90it/s]\n",
            "(24/29): Calibrating: 100%|██████████| 128/128 [00:17<00:00,  7.30it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [05:10<00:00, 103.51s/it]\n",
            "(24/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 78.99it/s]\n",
            "(25/29): Calibrating: 100%|██████████| 128/128 [00:04<00:00, 25.98it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [08:54<00:00, 178.18s/it]\n",
            "(25/29): Propagating: 100%|██████████| 128/128 [00:01<00:00, 77.62it/s]\n",
            "(26/29): Calibrating: 100%|██████████| 128/128 [00:04<00:00, 28.84it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [06:13<00:00, 124.56s/it]\n",
            "(26/29): Propagating: 100%|██████████| 128/128 [00:23<00:00,  5.48it/s]\n",
            "(27/29): Calibrating: 100%|██████████| 128/128 [00:05<00:00, 25.25it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [09:46<00:00, 195.38s/it]\n",
            "(27/29): Propagating: 100%|██████████| 128/128 [00:02<00:00, 57.16it/s]\n",
            "(28/29): Calibrating: 100%|██████████| 128/128 [00:04<00:00, 29.60it/s]\n",
            "Smoothing: 100%|██████████| 3/3 [07:45<00:00, 155.01s/it]\n",
            "(28/29): Propagating: 100%|██████████| 128/128 [00:11<00:00, 11.34it/s]\n",
            "(29/29): Calibrating: 100%|██████████| 128/128 [00:00<00:00, 306.53it/s]\n",
            "Smoothing: 0it [00:00, ?it/s]\n",
            "(29/29): Propagating: 100%|██████████| 128/128 [00:00<00:00, 904.36it/s]\n",
            "Smoothing: 0it [00:00, ?it/s]\n",
            "Calibrating weights: 196it [00:08, 22.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T09:17:58.322208+0800 | finalize | INFO - Compression lifecycle finalized for 1 modifiers\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-19T09:17:58.390265+0800 | get_model_compressor | INFO - skip_sparsity_compression_stats set to True. Skipping sparsity compression statistic calculations. No sparsity compressor will be applied.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Compressing model: 196it [00:03, 53.78it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'models/qwen2.5-1.5b-instruct-awq-llmc'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from llmcompressor.modifiers.awq import AWQModifier\n",
        "# 使用 llmcompressor 对 Qwen2.5-7B-Instruct 做 AWQ 量化\n",
        "\n",
        "awq_out_dir = \"models/qwen2.5-1.5b-instruct-awq-llmc\"\n",
        "\n",
        "awq_recipe = [\n",
        "    AWQModifier(\n",
        "        scheme=\"W4A16\",\n",
        "        targets=\"Linear\",\n",
        "        ignore=[\"lm_head\"],\n",
        "    ),\n",
        "]\n",
        "\n",
        "oneshot(\n",
        "    model=base_model_id,\n",
        "    dataset=\"open_platypus\",\n",
        "    recipe=awq_recipe,\n",
        "    output_dir=awq_out_dir,\n",
        "    max_seq_length=2048,\n",
        "    num_calibration_samples=128,\n",
        ")\n",
        "\n",
        "awq_out_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer you are loading from 'models/qwen2.5-1.5b-instruct-awq-llmc' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n",
            "Compressing model: 196it [00:00, 1146.78it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Qwen2ForCausalLM(\n",
              "  (model): Qwen2Model(\n",
              "    (embed_tokens): Embedding(151936, 1536)\n",
              "    (layers): ModuleList(\n",
              "      (0-27): 28 x Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2Attention(\n",
              "          (q_proj): CompressedLinear(in_features=1536, out_features=1536, bias=True)\n",
              "          (k_proj): CompressedLinear(in_features=1536, out_features=256, bias=True)\n",
              "          (v_proj): CompressedLinear(in_features=1536, out_features=256, bias=True)\n",
              "          (o_proj): CompressedLinear(in_features=1536, out_features=1536, bias=False)\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): CompressedLinear(in_features=1536, out_features=8960, bias=False)\n",
              "          (up_proj): CompressedLinear(in_features=1536, out_features=8960, bias=False)\n",
              "          (down_proj): CompressedLinear(in_features=8960, out_features=1536, bias=False)\n",
              "          (act_fn): SiLUActivation()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
              "    (rotary_emb): Qwen2RotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 加载 AWQ 量化后的检查点并做对话推理\n",
        "\n",
        "awq_tokenizer = AutoTokenizer.from_pretrained(awq_out_dir, trust_remote_code=True)\n",
        "if awq_tokenizer.pad_token_id is None:\n",
        "    awq_tokenizer.pad_token = awq_tokenizer.eos_token\n",
        "\n",
        "awq_model = AutoModelForCausalLM.from_pretrained(\n",
        "    awq_out_dir,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16,\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "awq_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AWQ q_proj layer type: <class 'compressed_tensors.linear.compressed_linear.CompressedLinear'>\n",
            "AWQ quantization_config: CompressedTensorsConfig {\n",
            "  \"config_groups\": {\n",
            "    \"group_0\": {\n",
            "      \"format\": \"pack-quantized\",\n",
            "      \"input_activations\": null,\n",
            "      \"output_activations\": null,\n",
            "      \"targets\": [\n",
            "        \"Linear\"\n",
            "      ],\n",
            "      \"weights\": {\n",
            "        \"actorder\": null,\n",
            "        \"block_structure\": null,\n",
            "        \"dynamic\": false,\n",
            "        \"group_size\": 128,\n",
            "        \"num_bits\": 4,\n",
            "        \"observer\": \"minmax\",\n",
            "        \"observer_kwargs\": {},\n",
            "        \"scale_dtype\": null,\n",
            "        \"strategy\": \"group\",\n",
            "        \"symmetric\": true,\n",
            "        \"type\": \"int\",\n",
            "        \"zp_dtype\": null\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  \"format\": \"pack-quantized\",\n",
            "  \"global_compression_ratio\": null,\n",
            "  \"ignore\": [\n",
            "    \"lm_head\"\n",
            "  ],\n",
            "  \"kv_cache_scheme\": null,\n",
            "  \"quantization_status\": \"compressed\"\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 检查 AWQ 量化是否生效：查看第 0 层 self_attn.q_proj 的类型和配置\n",
        "layer = awq_model.model.layers[0].self_attn.q_proj\n",
        "print(\"AWQ q_proj layer type:\", type(layer))\n",
        "print(\"AWQ quantization_config:\", getattr(awq_model.config, \"quantization_config\", None))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer you are loading from 'models/qwen2.5-1.5b-instruct-awq-llmc' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n",
            "Compressing model: 196it [00:00, 1314.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[AWQ] Q: 简单说说大模型量化有什么好处？\n",
            "A: 1. 提高计算效率：通过去除多余的参数和操作来降低模型的复杂度和内存占用。\n",
            "2. 降低成本：减少计算量可以降低硬件需求和功耗。\n",
            "3. 改善泛化能力：优化后的模型通常在一些任务上表现更优，能够更好地泛化到其他数据集。\n",
            "4. 实现可解释性：对量化后的模型进行分析可以理解其工作原理。\n",
            "5. 推广应用：适合于各种低资源环境下的部署。\n",
            "------------------------------------------------------------\n",
            "[AWQ] Q: Explain in English why activation-aware weight quantization (AWQ) can help LLMs.\n",
            "A: Activation-aware weight quantization (AWQ) helps large language models, or Large Language Models (LLMs), by improving their performance and efficiency while reducing the amount of computation required to run them.\n",
            "\n",
            "Here’s how AWQ works and why it is beneficial:\n",
            "\n",
            "1. **Reducing the Size of Model Parameters**: Activation-aware weight quantization involves mapping activations from a continuous range into a smaller discrete set. This process reduces the number of parameters needed for the model, which leads to smaller and more efficient models with fewer parameters.\n",
            "\n",
            "2. **Improving Performance**: Smaller models are often faster and use less memory, making them easier to train quickly and deploy on devices with limited resources. They also require less energy due to lower power consumption during inference.\n",
            "\n",
            "3. **Increased Efficiency**: By using fewer parameters, AWQ helps increase the overall efficiency of the model, meaning that the same level of accuracy can be achieved with significantly reduced computational requirements.\n",
            "\n",
            "4. **Better Robustness to Noise**: The discretized nature of the activations in AWQ makes the model more robust to noise in inputs, such as corrupted data or noisy environments, because the model's decision boundaries remain stable under these conditions.\n",
            "\n",
            "5. **Simpler Training Process**: Smaller models generally lead to simpler training processes,\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "AWQ_TEST_QUERIES = [\n",
        "    \"简单说说大模型量化有什么好处？\",\n",
        "    \"Explain in English why activation-aware weight quantization (AWQ) can help LLMs.\",\n",
        "]\n",
        "\n",
        "@torch.no_grad()\n",
        "def awq_chat(question: str) -> str:\n",
        "    msgs = [\n",
        "        {\"role\": \"system\", \"content\": \"你是一名 AI 助手，回答准确、简洁。\"},\n",
        "        {\"role\": \"user\", \"content\": question},\n",
        "    ]\n",
        "    input_ids = awq_tokenizer.apply_chat_template(\n",
        "        msgs,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=True,\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(awq_model.device)\n",
        "\n",
        "    gen_ids = awq_model.generate(\n",
        "        input_ids=input_ids,\n",
        "        max_new_tokens=256,\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        repetition_penalty=1.1,\n",
        "        eos_token_id=awq_tokenizer.eos_token_id,\n",
        "        pad_token_id=awq_tokenizer.pad_token_id,\n",
        "    )\n",
        "    out_ids = gen_ids[0, input_ids.shape[-1]:]\n",
        "    return awq_tokenizer.decode(out_ids, skip_special_tokens=True).strip()\n",
        "\n",
        "for q in AWQ_TEST_QUERIES:\n",
        "    ans = awq_chat(q)\n",
        "    print(f\"[AWQ] Q: {q}\\nA: {ans}\\n\" + \"-\" * 60)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "peft",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
